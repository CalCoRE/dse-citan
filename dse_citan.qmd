---
title: "dse-citan"
author: "removed for review"
format: 
  html:
    code-fold: true
    code-summary: "Show the code"
editor: visual
theme: minty
bibliography: references.bib
csl: apa-6th-edition.csl
---

# Mapping the Scholarly Foundations of "Data Science Education"

As readers of HDSR know well, there is wide diversity in who is involved in data science education research and how it is conceptualized. Special conference sessions and journal issues have emerged across multiple fields including Computer Science, Statistics, Information and Library Sciences, Education, and the Learning Sciences.

Navigating this landscape can be challenging, since these domains all bring different intellectual foundations, motivations, and practical considerations. For example,

In just the past year, we have learned much about this landscape. Mike et al [-@mike2023] leveraged k-means clustering techniques to classify a collection of over 1,000 data science education papers to identify what are key topics of this emerging field, given its multidisciplinary nature. They identified five key foci: curriculum; pedagogy; STEM skills; domain adaptation; and social aspects. Rosenberg and Jones [-@rosenberg2024] presented an analysis of three recent journal special issues (a total of 28 papers and their shared references) dedicated more specifically to the study of learning in K-12 data science. They found that despite their shared topical focus, each special issue reflected distinct orientations toward the field and with different degrees of cohesiveness in the works cited within each.

In this paper, I present a "meso" level analysis that connects the focused micro-reference patterns of the sort examined in Rosenberg & Jones [-@rosenberg2024] to the broad emerging topics of the sort illuminated by Mike et al's [-@mike2023] macro-analysis. It does so through a mixed-methods investigation of 288 indexed works that identify themselves in their title, keywords, or abstract as specifically concerned with "data science education," and the reference co-citation network of over 8,000 works that form the foundations of that scholarship.

Leveraging bibliometric and network analytic methods, I have identified distinct and conceptually coherent clusters of foundational work upon which this emerging literature is built. These clusters map to specific disciplinary communities and publication venues. Through additional qualitative content analysis, I explore how these these point to specific communities, methodologies, and topics reflected in the current literature. In particular, I identify some areas of divison between undergraduate and K-12 data science education efforts, as well as between K-12 efforts emerging from different subfields. Raising awareness of these separations and encouraging deeper engagement across subcommunities can help build stronger and more coherent trajectories for data science education.

## 1. Why Map Data Science Education Scholarship?

A number of recent works have highlighted the proliferation of "data science education" across multiple fields.

### 1.1. Data Science Education as an Interdisciplinary Field

Carmichael Data Science cs Statistics Two Cultures

```         
CETINKAYA-RUNDEL M DANYLUK A FORBES J POSNER M BUILDING BRIDGES FOR DATA SCIENCE EDUCATION PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION SIGCSE 19 2019
```

```         
MSWELI NT MAWELA T TWINOMURINZI H DATA SCIENCE EDUCATION–A SCOPING REVIEW JOURNAL OF INFORMATION TECHNOLOGY EDUCATION RESEARCH 22 PP 263-294 2023
```

|  |  |
|------------------------------------|------------------------------------|
| MEMARIAN B, 2024, EDUC INF TECHNOL | DATA SCIENCE PEDAGOGICAL TOOLS AND PRACTICES: A SYSTEMATIC LITERATURE REVIEW |

### 1.2. Bibliometric Mapping to Understand "Voluminous, Fragmented" Fields

Science mapping is a particular form of bibliometric analysis that leverages data from published works to characterize the structure of scholarly fields of study. In particular, science mapping is useful for understanding the development of fields that are "." In this paper, I rely on bibliographic document co-citation analysis; this is considered one of the most used and validated bibliometric methods [@zupic2015]. Because co-citation analysis reflects bodies of work that are connected gradually over time, this sort of analysis is more appropriate to understand what Zuipc \[xxx\] describes as the "knowledge base clusters" that inform current work.

From zupic:

It is the most used and validated bibliometric method. Connecting documents, authors or journals with co-citation has been shown to be reliable. Since citation is a measure of influence it offers a method to filter the most important works.

Co-citation is performed on cited articles so it is not optimal for mapping research fronts. Citations take time to accumulate so new publications cannot be connected directly but only through knowledge base clusters. Several citations are needed to map articles so it is impossible to map articles which are not cited much. When performing author co-citation analysis on SSCI (WOS) data, only first-author information is available.

Complement with bibliographic coupling (exemplars only)

Immediately available: does not require citations to accumulate. Can be used for new publications which are not cited yet, emerging fields and smaller subfields.

It can only be used for limited timeframe (up to a five-year interval). It does not inherently identify the most important works by citation counts as cocitation; it is difficult to know whether mapped publications are important or not.

Haustein and Larivière emphasize the dangers of an over-reliance on bibliometric methods to describe disciplines. I intentionally focus on structural features of co-citation, without attention to specific authors, over-reliance on citation frequency, or other.

## 2. Constructing the Bibliographic Datasets

For this analysis, I make extensive use of the R `bibliometrix` package [@aria2017], along with the `dplyr` package for data handling [@wickham2023], and the `stringr` and `textTools` packages to process and compare scholarly reference records. The `DT` package [@dt:awr2024] and VOSviewer software [@vaneck2010] are used to generate displays and visualizations.

```{r}
#| label: load-packages-and-scripts
#| warning: false

# for the analysis
library(bibliometrix)

# for working with data
library(dplyr)
library(stringr)
library(textTools)

# for a pretty document
library(DT)
```

Consistent with the bibliometric co-citation methods described in Section 1.2, my analysis focuses on three interrelated datasets (also illustrated in [Figure 1](#data-sources)). I introduce them briefly here, and offer more detail about their construction and cleaning in the following sections.

-   A collection called `coreDSEworks` describes the set of scholarly works selected to represent the core, emerging data science education literature. These are indexed academic publications that feature the full phrase "data science education" in the title, abstract, or keywords.

-   A second, much larger collection of scholarly works called `refWorks` represents all papers that are cited by, and are therefore taken to represent the intellectual foundations of, the emerging data science education literature. This dataset is constructed by extracting references from the bibliographies of each record in `coreDSEworks`. It is reasonable to expect that some papers will appear in both the coreDSEworks and refWorks datasets.

-   Finally, `bibNetwork` describes a weighted document co-citation network of `refWorks`. It represents each record in `refWorks` as a node in the network. The more frequently a given reference document is cited by the core works, the higher the weight of the corresponding node in `bibNetwork`. Two nodes in the network are connected by an edge when both works appear in the reference list of the same core document (A, B, C, etc.). The more frequently two nodes appear together in the reference lists of core documents, the heavier the weight of the corresponding edge.

![Figure 1. Three key data frames: coreDSEworks, refWorks that are cited in the coreDSEworks, and the bibNetwork that represents co-citation patterns of refWorks.](dse_citan_files/datasources.png){#data-sources width="500"}

### 2.1 Identifying Core Data Science Education Publications

To conduct this review, I selected an intentionally narrow, but relevant and well-specified set of initial works to form the “core” set of papers meant to represent the field: publications that are indexed in either Scopus or Clarivate Analytics Web of Science and that include the specific full phrase “data science education” in the title, abstract, or keywords. As of Dec 9, 2024, this query yielded a total of 287 records after screening to remove duplicates and inappropriate records. Records deemed inappropriate included one correction statement (for which the corrected report remained included), one retraction statement and the corresponding retracted article, four full conference review records, and one full poster session review record. For each of the four excluded conference proceedings records, I confirmed that the more specific corresponding record included in the full review was included instead. For the excluded poster session review record, corresponding poster records were not available. None of the five review records that were removed included cited reference information. [Figure 2](#prisma-fig) features a PRISMA diagram describing the construction of the `coreDSEworks` corpus.

![PRISMA diagram describing construction of the coreDSEworks corpus](dse_citan_files/prisma.png){#prisma-fig width="500"}

Of the publication records that are included in the coreDSEworks corpus, seven records do not include information about cited references. Manual inspection reveals that these records are editorials and commentaries. These works represent substantive contributions to the literature, and provide information about the venues and authors that are actively contributing to the “data science education” discourse. Therefore, they were not excluded from the coreDSEworks corpus. However, because they works do not include references, only 280 records directly impact the construction of the reference works dataset and the reference co-citation network that are described in the following sections.

```{r}
#| label: get-core-works
#| output: false

source("scripts/read_works.R")
coreDSEworks <- getCoreDSEWorks()
```

While the focus of this paper is not on the core works themselves, it is useful to briefly review some key descriptive characteristics of the coreDSEworks collection to determine its validity for this analysis. The histogram featured in Figure 3 reflects the nascent nature of this area of study, with the first publication appearing in 2012 and relatively steady growth since then.

```{r}
#| label: show-pub-years

hist(coreDSEworks$PY)
```

The titles, authors, publication venues, and publication years of each `coreDSEworks` record is presented in randomized order below:

```{r}
#| label: display-core-works

datatable(coreDSEworks[
  sample(1:nrow(coreDSEworks)), 
  c(4,1,6,5)],
  rownames=FALSE,
  options=list(pageLength=5),
  style='bootstrap',
  class='table-condensed smaller table-striped'
  )
```

Of the publication records that are included in the coreDSEworks corpus, 7 records do not include information about cited references. These records are editorials and commentaries. These works represent substantive contributions to the literature and provide information about the venues and authors that are actively contributing to the "data science education" discourse. Therefore, they were not excluded from the `coreDSEworks` corpus. However, because they works do not include references, only 277 records comprise the basis of the reference co-citation analysis component described next.

### 2.2. Extracting and Cleaning DSE Reference Works

Next, we can construct a new dataset refWorks to represent the full set of foundational works from which the "data science education" literature represented by coreDSEworks draws. This is done by extracting the full reference lists of each coreDSEworks paper.

```{r}
#| label: extract-reference-works
#| warnings: false

refWorks <- as.data.frame(
  citations(coreDSEworks, field = "article", sep = ";")$Cited)
```

However, as noted by [@mike2023], this process is not straightforward—especially when dealing with publications from dramatically different fields. The reference lists included in Scopus and WoS databases are text-only, and the reference formats that are used across the disciplines engaged in data science education (e.g. ACM, APA, IEEE) are quite different. Therefore, the process of cleaning the refWorks list to ensure that references are matched and properly counted and linked is not trivial. This is especially true for papers that are more visible (and are therefore more likely to shape our understanding of the field). Since these papers are picked up by different scholarly communities, they are more likely to be cited in multiple formats that cannot be easily matched with one another while preserving genuine distinctions with other similarly titled work. Consider, for example, the list of records below, most of which represent the same National Academies' [-@medicine2018] report *Data Science for Undergraduates: Opportunities and Options* listed below.

```{r}
#| label: demo-duplicates
#| output: false

showabit <- refWorks %>% filter( CR %like% "DATA SCIENCE FOR UNDERGRADUATES" ) %>% head(20)
datatable(showabit, 
  rownames=FALSE,
  options=list(pageLength=20),
  style='bootstrap',
  class='table-condensed small table-striped'
  )
```

If records such as the ones above are not consolidated, the well-known *Data Science for Undergraduates* report would be represented in the network as several isolated papers, each with only marginal impact on the field as a whole. To address this problem of duplicate records and ensure that the resulting reference co-citation network is accurate, I turn refWorks into a lookup table. Using a combination of methods including removal of special characters, automated text matching, and a manual dictionary of duplicate records screened by author and year, each text reference is mapped to a single parent format.

```{r}
#| label: generate-lookup-table
#| output: false

source("scripts/clean_refs.R")
charExcludeList <- '[\r\n\\:\\(\\)+\\?\\|\\"\\“\\”\\,\'\\`\\‘\\.\\*\\’]'
refWorks$CR <- gsub(charExcludeList,'',refWorks$CR) # the original cited works

refWorks$correctedCR <- ""
refWorks$freqAgg <- refWorks$Freq

refWorks <- cleanSpecialChars(refWorks) 
refWorks <- cleanManualDuplicates(refWorks) 
refWorks <- autoMatch(refWorks,.75)
```

Finally, the lookup table is used to replace all duplicate versions of a given reference that appear in the original coreDSEworks dataframe with the corrected version. This ensures that when the reference citation analysis is applied to the coreDSEworks, all versions of citations that correspond to a given reference are appropriately consolidated in the construction of the reference network and associated node measures.

```{r}
#| label: tally-corrected-refs-in-coreDSEworks
#| output: false

# Replace refs lists in the core works datatable with cleaned refs
coreDSEworks <- rewriteCleanRefs(coreDSEworks,charExcludeList)

# update frequencies given found matches in coreDSEworks
refWorks <- correctFrequenciesCited(refWorks,coreDSEworks)
```

After consolidating citation counts across duplicate records in this way, the relative positions of different cited reference works changes substantially. Tab 3 of Fig 2 features the top 100 records in the lookup table with corrected citation counts, again ordered by frequency of citations. The differences between the original refWorks table and the corrected table demonstrate the importance of such records consolidation; the [-@medicine2018] *Data Science for Undergraduates* reference that was originally listed as the most frequently referenced citation is superseded by DeVeaux et al's [-@deveaux2017] curriculum guidelines. Similarly, several other works in the original top 10 list change position or are even replaced by others.

```{r}
#| label: show-corrected-refs

datatable(refWorks[c(3,5)] %>% arrange(desc(refWorks$freqCit)) %>% head(20), 
  rownames=FALSE,
  options=list(pageLength=5),
  style='bootstrap',
  class='table-condensed small table-striped'
)
```

#### Indexing Between Core DSE Publications and Reference Work

Shortnames function as an index to connect cited reference records in refWorks to their corresponding citing coreDSEworks. These replicate the format used by the bibliometrix analysis package when generating the cited reference network: author last name, author first initial(s), year of publication. This allows me to map insights from analysis of `bibNetwork` back to the more complete reference records in `refWorks`, and to identify . It also allows me to identify which `coreDSEworks` records demonstrate particular structural relationships to the underlying reference networks. For example, I use `bibNetwork` shortnames to identify which `coreDSEworks` draw predominantly from only one of the clusters identified in the reference work network analysis, versus which draw in a more balanced way from all three clusters.

```{r}
#| label: generate-shortnames

source("scripts/shortnames.R")
# create shortnames and add them as a new ref list to coreDSEworks
refWorks <- refShortNames(refWorks)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)
```

In cases where more than one reference exists from the same first author in the same year, shortnames are appended with a number, by descending citation frequency. This, too, replicates shortnames as they appear in the `refNetwork`. For example, below are shortnames for multiple distinct reference works in 2018, for which R Biehler served as first author:

```{r}
#| label: illustrate-shortnames

biehler <- refWorks %>% filter(shortname %like% "biehler r 2018")

datatable(biehler[c(1,5,6)] %>%
            filter(freqCit > 0) %>%
            arrange(desc(freqCit)), 
            rownames=FALSE,
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )
```

# Constructing the DSE Reference Co-Citation Network

Finally, I use the `biblioNetwork` function within the R `bibliometrix` package. This function is applied to the *cleaned* reference records of `coreDSEworks`; that is, the duplicated records that were originally extracted from the reference lists have been replaced with the cleaned, consolidated records and will be appropriately aggregated in the construction of the final reference document co-citation network. Only references that are cited at least 3 times are included in the analysis, to reduce the influence of isolated papers in favor of identifying repeated trends in the literature.

```{r}
#| label: generate-ref-net
# build co-citation network of DSE cited works
refMatrix <- biblioNetwork(coreDSEworks, analysis = "co-citation",
                           network = "references", sep = "; ")
```

Fig 3 features a visualization of the reference co-citation network of all papers that are cited at by at least 3 distinct core DSE works. In both representations, three distinct clusters can be identified: a green cluster to the left of both \[XXX\]

```{r}
#| label: visualize-ref-net

inclusion.cite.count = 2
cutoff = as.integer(count(refWorks %>% 
                            filter(freqCit>inclusion.cite.count)))
refNet=networkPlot(refMatrix, n = cutoff,
                   Title = "Co-Citation Network of Top DSE Reference Works",
                   size.cex=TRUE, size=15, remove.multiple=FALSE,
                   remove.isolates = TRUE, labelsize=.7, edgesize = 5,
                   edges.min=0, type = "fruchterman", cluster = "louvain",
                   community.repulsion = .04)
# louvain clustering seeks community membership

# we created shortnames for all duplicates, but refNet will 
# only create shortnames for items that are cited at least the 
# inclusion.cite.count number of times. Let's update to that.
refWorks <- refShortNames(refWorks,inclusion.cite.count)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)
```

While these two visualization formats are intended to highlight different features of the network structure, both identify the same three main clusters. Consistent with research on bibliometric citation network analysis (e.g. XXX), I conceptualize of these three clusters as representing distinct intellectual communities that together form the foundations of the Data Science Education literature. The remainder of this paper examines the nature of these communities and the similarities and differences among them.

## Structural Foundations of Data Science Education

In the remainder of the results section, I first present an analysis of the structure and content of the reference network itself, to better understand the scholarly foundations of "Data Science Education". I explore the most highly cited "broker works" of this network---that is, the papers that connect across the otherwise distinct clusters in the network--- as well as the most highly cited "hub works" specific to each of the three clusters, to better understand which references distinguish these clusters from one another.

### DSE Broker Works

In network science, a *broker* describes a node in a network that connects otherwise distinct communities. These nodes are characterized by high betweenness centrality measures. When applied to bibliographic networks, broker works reflect papers that are referenced alongside papers that belong to otherwise distinct reference clusters. This can signal higher visibility or relevance of these works as bridges across scholarly communities.

The top ten broker works as identified by betweenness centrality are featured in Fig X. This collection includes well-known articles that work to define the nature of data science as a field [@conway2010][@cleveland2001][@donoho2017][@berman2018], and that present frameworks and guidelines to ensure that new data science training programs support the development of key skills that students involved in data fields should learn, and how they intersect with industry [@demchenko2016;\@irizarry2020][@nationalacademiesofsciencesengineeringandmedicine2018][@deveaux2017][@anderson2014].

```{r}
#| label: pull-top-brokers

# select the most "between" reference works. Show the top ten
# and include the top 50
refBrokers <- refNet[["cluster_res"]] %>% 
  arrange(desc(btw_centrality)) %>%
  head(50)

# use shortnames to identify the full citation for each
# reference broker work from the refWorks data frame
refBrokers$vertex <- paste0(
  word(refBrokers$vertex,1), " ",
  str_sub(word(refBrokers$vertex,2),1,1), " ",
  word(refBrokers$vertex,3))

# refNet is shortnaming these with appendix; manually fix for the join
refBrokers$vertex[refBrokers$vertex=="demchenko y 2016"] <- "demchenko y 2016-1"
refBrokers$vertex[refBrokers$vertex=="anderson p 2014-1"] <- "anderson p 2014"

relevantRefs <- refWorks %>% 
  filter(shortname %in% refBrokers$vertex) %>% 
  filter(freqCit > inclusion.cite.count) %>% 
  arrange(desc(freqCit))

datatable(left_join(refBrokers, relevantRefs, by=c("vertex"="shortname") )[c(3,8,10)],
            rownames=FALSE,
            options=list(pageLength=10),
            style='bootstrap',
            class='table-condensed small table-striped'
            )
```

As is evident in the table, the most frequently cited "broker" reference works are [@deveaux2017; @medicine2018; @cleveland2001]

In general, betweenness centrality is expected to reproduce citqtion frequency. However, while many of the broker works are also frequently cited, many of the most frequently cited works do not appear in the top ten broker works, and some less frequently cited works do. For example, [@dasgupta2017] is only cite 6 times but is identified as a broker work. This means that because though it is less frequently cited, it has been cited by works that otherwise draw heavily from one one of the three smaller networked communites we describe in the following section. This reinforces the isolated nature of the three communities.

### Three Distinct Collections of DSE Scholarly Foundations

While broker works establish what different scholarly communities cite in common, identifying "hub" works that are only cited frequently alongside papers in each cluster can help highlight what distinguishes one scholarly community from another. Below, I work to characterize these communities by identifying, for each, a number of key characteristics including (1)

```{r}
#| label: prepare-to-extract-clusters

y <- refNet[["cluster_res"]]$btw_centrality
y[y==0] <- NA

# set the cutoff to lowest 75th percentile in terms of betweenness centrality
btw_cutoff <- quantile(y,c(.75),na.rm=TRUE)

referenceClusterAuthors <- refNet[["cluster_res"]] %>%
  # restrict this to only authors of papers that are not very connected
  # outside of their specific cluster
  #filter( btw_centrality < mean(refNet[["cluster_res"]]$btw_centrality) ) %>%
  filter( btw_centrality < btw_cutoff ) %>%
  group_by(cluster) %>%
  summarize(authors = list(
    paste(
      word(vertex,1),  # first word (last name)
      str_sub(word(vertex,2),1,1),     # second word (first initial)
      word(vertex,3) )
    )
  )

getClusterHub <- function(i) {
  clusterLookup <- referenceClusterAuthors$authors[[i]]
  return( refWorks %>%
    filter( !is.na( shortname ) ) %>% 
    filter( shortname %in% clusterLookup ) %>%
    filter( freqCit > 0 ) %>%
    arrange( desc(freqCit) ) )
}

# add $refInfo as quick lookup for what cluster the refs belong to
for( i in 1:nrow(coreDSEworks) ) {
  coreDSEworks$refInfo[i] <- refNet[["cluster_res"]] %>% 
       filter( str_detect(vertex, coreDSEworks$shortnameRefs[i]) == TRUE ) %>% 
    select(cluster)
}

getHeavyCitingWorks <- function(coreDSEworks,n,range="[1-3]") {
  # filter to look at works citing at least 5 DSE refWorks
  coreCitingWorks <- coreDSEworks %>% 
    filter( str_count(coreDSEworks$refInfo,range) > 5 )
  
  # then only include those that have >75% reWorks from cluster n
  coreCitingWorks <- coreCitingWorks %>% 
    filter( str_count(coreCitingWorks$refInfo,as.character(n))
            /str_count(coreCitingWorks$refInfo,range) > .75 )
  
  return( coreCitingWorks )
}

```

#### Community 1: A Focus on Data Science Undergraduate Majors

One community is comprised of works that speak to curriculum development and strategies to introduce data science to specialists at the postsecondary level. The majority of publications are from journals that focus on Statistics and Information Sciences. It also includes papers focused on active learning techniques (CITE), and specific tools used for data work (CITE). Methodological papers include

```{r}
datatable(getClusterHub(1)[c(3,5)], 
            rownames=FALSE,
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )
```

In terms of audience and content,

In terms of pedagogy and methodology,

```{r}
#| label: find-citing-core-works-cluster1

coreCitingWorks1 <- getHeavyCitingWorks(coreDSEworks,1)

datatable(coreCitingWorks1[c(4,6)],
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )

coreBibAnalysis <- biblioAnalysis(data.frame(coreCitingWorks1))
summary(coreBibAnalysis)
```

#### Community 2: A Focus on K-12 Students and the Learning Sciences

The second community is comprised of paper that focus on introducing data literacy and data science skills to non-majors, including at the university and pre-college levels.

```{r}
datatable(getClusterHub(2)[c(3,5)], 
            rownames=FALSE,
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )
```

In terms of audience and content,

In terms of pedagogy and methodology,

```{r}
#| label: find-citing-core-works-cluster2

coreCitingWorks2 <- getHeavyCitingWorks(coreDSEworks,2)

datatable(coreCitingWorks2[c(4,6)],
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )

coreBibAnalysis <- biblioAnalysis(data.frame(coreCitingWorks2))
summary(coreBibAnalysis)
```

#### Community 3: A Focus on Computational Approaches to Data for Non-Majors

The third community is comprised of researchers who are focused on introducing data science at the K-12 level, with a primary focus on the computational aspects of data science.

```{r}
datatable(getClusterHub(3)[c(3,5)], 
            rownames=FALSE,
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )
```

In terms of audience and content,

In terms of pedagogy and methodology,

```{r}
#| label: find-citing-core-works-cluster3

coreCitingWorks3 <- getHeavyCitingWorks(coreDSEworks,3)

datatable(coreCitingWorks3[c(4,6)],
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )
```

### Core DSE Works that Bridge Communities

Finally, to better understand the relationship between the reference co-citation network itself and the core Data Science Education literature, I present a deeper analysis of *how* core DSE works draw from these different clusters of literature. I present an analysis of recently published Data Science Education papers that draw heavily from While the reference co-citation network represents the scholarly foundations of what currently constitutes the "Data Science Education" literature, many of the works in this network predate the emergence of the field, and many deal with proximally or even more distally related topics (e.g. Statistics Education, Learning Theory, Education Research Methodologies).

```{r}
#| label: find-bridging-works
#| warning: false

bridges <- coreDSEworks %>% 
  filter( str_count(coreDSEworks$refInfo,"[1-3]") > 5 )
  
bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("1"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("2"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("3"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

datatable(bridges[c(4,6)],
            options=list(pageLength=5),
            style='bootstrap',
            class='table-condensed small table-striped'
            )
```

# Discussion

This analysis also highlights a few shared areas of concern across all areas. One, for example, concerns issues of ethics in the teaching and learning of data science. This appears frequently in broker works (e.g., XXX) as well as in popular works within each community (xxx). While not the focus of the current analysis, it is also worth noting that a collection of more popular academic books including *Race After Technology*, *Weapons of Math Destruction* [-@oneil2016]*, Data Feminism*, and *Algorithms of Oppression* [-@noble2018]

This analysis also suggests that the emerging data science education field would benefit from literature search methods that span different publication venues. For example, both Cluster 2 (Education and Learning Sciences) and Cluster 3 (Data Science for Non-Majors) feature several reports on the design and enactment of K-12 data science learning environments. However, these reports appear in notably different publication fora, with the former group of work appearing primarily in Learning Sciences and Education journals, and the latter appearing primarily in conference proceedings, particularly those associated with the computer science field.

Bridging Toward More Coherent Data Science Education Trajectories

XXX

Limitations. Still a small field, and working with small numbers. Some of the relationships observed here may be driven by one or a few paprs (e.g., certain research groups whose output reproduces particular citation patterns across papers). Also important to recognize the impact of time, older papers have more time to be picked up and cited than new papers. Good for understanding the foundations so far, but not necessarily for predicting how these fields will develop moving forward.

# References
