---
title: "dse-citan"
author: "removed for review"
format: 
  html:
    toc: true
    code-fold: true
    code-summary: "Show the code"
    embed-resources: true
editor: visual
bibliography: references.bib
csl: apa.csl
---

# The Many Worlds of "Data Science Education"

As readers of HDSR know well, there is wide diversity in who is involved in data science education research and how it is conceptualized (e.g., X, Y). Navigating this landscape can be challenging, especially for those who are just entering the field or who seek complementary insights from other related domains. Different academic communities may use different terminology, or they may hold different conceptualizations for the same key terms, "talking past" one another. For example, Rosenberg & Jones (2024) present vignettes illustrating substantially different visions of what might constitute "data science education" at the K-12 level, reflecting the differing emphases of three recent special issues devoted to the topic. Publication practices and norms also differ across fields, making it harder for researchers to find relevant work. Meanwhile, there are still only a few venues (including the Harvard Data Science Review and the Journal of Statistics and Data Science Education) that specifically promote data science education as an area of focus (xxx).

Despite these ongoing challenges, there is a general consensus that it is time to take stock and build common understandings of data science education as a field in its own right. This report contributes to these efforts by presenting a mixed-methods investigation of 287 papers that explicitly identify themselves in their title, keywords, or abstract as concerned with “data science education.” I use these works to construct a reference co-citation network from over 7,000 works extracted from these core papers' reference lists that, together, form the *de facto* foundations of data science education scholarship.

Analysis of the co-citation network and the works emerging from distinct suggests that while there are some shared (but not-so-shared) "broker" references that are broadly cited within the emerging data science education literature, three distinctive and conceptually coherent, but somewhat isolated clusters of reference works emerge. With attention to the audiences, themes, pedagogy, and methodologies emphasized within each cluster, I identify areas of agreement and divergence across these clusters. Some areas of disconnect include at the boundary between undergraduate and K-12 data science education efforts, as well as between different K-12 initiatives.

My goal is to raise awareness of the diversity of communities working on data science education, and to encourage deeper engagement with literature and researchers across these communities. In that spirit, this report is accompanied by an interactive open-source document that readers can use to peruse the many worlds of data science education. Understanding what we can learn from each other can support stronger, more coherent trajectories for future data science students, as well as for all students who will find themselves navigating a data-filled world.

## 1. Why Map Data Science Education Scholarship?

A number of recent works have highlighted the proliferation of "data science education" across multiple fields.

### 1.1. The Interdisciplinarity of Data Science Education

Carmichael Data Science cs Statistics Two Cultures

|  |  |
|------------------------------------|------------------------------------|
| MEMARIAN B, 2024, EDUC INF TECHNOL | DATA SCIENCE PEDAGOGICAL TOOLS AND PRACTICES: A SYSTEMATIC LITERATURE REVIEW |

Despite these challenges, we have learned much about this landscape in recent years. Mike et al [-@mike2023] leveraged k-means clustering techniques to classify a collection of over 1,000 data science education papers to identify what are key topics of this emerging field, given its multidisciplinary nature. They identified five key foci: curriculum; pedagogy; STEM skills; domain adaptation; and social aspects. Rosenberg and Jones [-@rosenberg2024] presented an analysis of three recent journal special issues (a total of 28 papers and their shared references) dedicated more specifically to the study of learning in K-12 data science. They found that despite their shared topical focus, each special issue reflected distinct orientations toward the field and with different degrees of cohesiveness in the works cited within each.

There have also been efforts to bring some of these communities closer together. A pair of workshops offered in 2019 at the ACM's Special Interest Group in Computer Science Educuation () and at the Joint Statistical Meetings () sought to foster collaboration between disciplines focused on undergraduate data science programs of study.

Further intersections with information and library sciences, and with social sciences and humanities as people attend to the ethical and civic implications of increased access to data.

In this paper, I offer a "meso" level examination that helps to connect the sort of divergent literature reference patterns of the sort examined in Rosenberg & Jones [-@rosenberg2024] to the broad emerging topics of the sort illuminated by Mike et al's [-@mike2023] macro-analysis. It does so through a mixed-methods investigation of 288 indexed works that identify themselves in their title, keywords, or abstract as specifically concerned with "data science education," and the reference co-citation network of over 8,000 works that form the foundations of that scholarship.

### 1.2. Bibliometric Mapping to Understand "Voluminous, Fragmented" Fields

Science mapping is a particular form of bibliometric analysis that leverages data from published works to characterize the structure of scholarly fields of study. In particular, science mapping is useful for understanding the development of fields that are "." In this paper, I rely on bibliographic document co-citation analysis; this is considered one of the most used and validated bibliometric methods [@zupic2015]. Because co-citation analysis reflects bodies of work that are connected gradually over time, this sort of analysis is more appropriate to understand what Zuipc \[xxx\] describes as the "knowledge base clusters" that inform current work.

Science mapping is a valuable approach in bibliometric analysis that uses metadata from published works to elucidate the structure of scholarly fields, particularly those undergoing dynamic development. In this study, we utilize bibliographic document co-citation analysis, one of the most widely used and validated bibliometric methods (Zupic, xxx). Co-citation analysis identifies connections between documents based on their shared citations over time, as as determined by their mutual appearances in the reference lists of some set of focal documents. thereby revealing the "knowledge base clusters" that underpin current research (Zupic).

To supplement co-citation analysis, we can also employ bibliographic coupling. Unlike co-citation analysis, bibliographic coupling is immediately available and does not require citations to accumulate (Haustein & Larivière, 2017). It can be used for new publications that are not yet cited and for emerging fields and smaller subfields. However, it is limited to a five-year interval (Haustein & Larivière). It does not inherently identify the most important works by citation counts, making it challenging to determine whether mapped publications are indeed significant or not (Haustein & Larivière).

Co-citation is performed on cited articles so it is not optimal for mapping research fronts. Citations take time to accumulate so new publications cannot be connected directly but only through knowledge base clusters. Several citations are needed to map articles so it is impossible to map articles which are not cited much. When performing author co-citation analysis on SSCI (WOS) data, only first-author information is available.

Immediately available: does not require citations to accumulate. Can be used for new publications which are not cited yet, emerging fields and smaller subfields.

Haustein and Larivière emphasize the dangers of an over-reliance on bibliometric methods to describe disciplines. I intentionally focus on structural features of co-citation, without attention to specific authors, over-reliance on citation frequency, or other.

## 2. Constructing the Bibliographic Datasets

This research leverages the R `bibliometrix` package [@aria2017] for constructing, analyzing, and visualizing bibliographic records. I use the `dplyr` package for data handling [@wickham2023], and the `stringr` and `textTools` packages to process and compare scholarly reference records. The `DT` package [@dt:awr2024] is used to generate interactive data displays.

```{r}
#| label: load-packages-and-scripts
#| warning: false

# for the analysis
library(bibliometrix)

# for working with data
library(dplyr)
library(stringr)
library(textTools)

# for a pretty document
library(DT)
```

Consistent with the bibliometric co-citation methods described in Section 1.2, this analysis focuses on three interrelated datasets (also illustrated in [Figure 1](#data-sources)).

-   A collection called `coreDSEworks` describes a core set of 287 scholarly works selected to represent the core, emerging data science education literature. These are indexed academic publications that feature the full phrase "data science education" in the title, abstract, or keywords.

-   A second, much larger collection of scholarly works called `refWorks` represents \[xxx\] distinct papers that are cited by, and are therefore constitute the *de facto* intellectual foundations of, the emerging data science education literature. This dataset is constructed by extracting references from the bibliographies of each record in `coreDSEworks`. Since papers in `coreDSEworks` cite one another, many appear in both datasets.

-   Finally, `bibNetwork` describes a weighted document co-citation network of `refWorks`. It represents each record in `refWorks` as a node in the network. The more frequently a given reference document is cited by the core works, the higher the weight of the corresponding node in `bibNetwork`. Two nodes in the network are connected by an edge when both works appear in the reference list of the same core document (A, B, C, etc.). The more frequently two nodes appear together in the reference lists of core documents, the heavier the weight of the corresponding edge.

![Figure 1. Three key data frames: coreDSEworks, refWorks that are cited in the coreDSEworks, and the bibNetwork that represents co-citation patterns of refWorks.](dse_citan_files/datasources.png){#data-sources width="600"}

### 2.1 Identifying Core Data Science Education Publications

To conduct this review, I selected an intentionally narrow, but relevant and well-specified set of initial works to form the “core” set of papers meant to represent the field: publications that are indexed in either Scopus or Clarivate Analytics Web of Science ("WoS") and that include the specific full phrase “data science education” in the title, abstract, or keywords. As of Dec 9, 2024, this query yielded a total of 287 records after screening to remove duplicates and inappropriate records. Records deemed inappropriate included one correction statement (for which the corrected report remained included), one retraction statement and the corresponding retracted article, four full conference review records, and one full poster session review record. For each of the four excluded conference proceedings records, I confirmed that the more specific corresponding record included in the full review was included instead. For the excluded poster session review record, corresponding poster records were not available. None of the five review records that were removed included cited reference information. [Figure 2](#prisma-fig) features a PRISMA diagram describing the construction of the `coreDSEworks` corpus.

![PRISMA diagram describing construction of the coreDSEworks corpus](dse_citan_files/prisma.png){#prisma-fig width="600"}

```{r}
#| label: get-core-works
#| output: false

source("scripts/read_works.R")
coreDSEworks <- getCoreDSEWorks()
```

While the focus of this paper is not on the core works themselves, it is useful to briefly review some key descriptive characteristics of the coreDSEworks collection to determine its validity for this analysis. The histogram featured in Figure 3 reflects the nascent nature of this area of study, with the first publication appearing in 2012 and relatively steady growth since then.

```{r}
#| label: show-pub-years

hist(coreDSEworks$PY)
```

The titles, authors, publication venues, and publication years of each `coreDSEworks` record is presented in randomized order below:

```{r}
#| label: display-core-works

datatable(coreDSEworks[
  sample(1:nrow(coreDSEworks)), 
  c(4,1,6,5)])
# ,
#   rownames=FALSE,
#   options=list(pageLength=5),
#   style='bootstrap',
#   class='table-condensed small table-striped'
#   )
```

Of the 287 publication records that are not excluded from the coreDSEworks corpus, seven do not include information about cited references. Manual inspection reveals that these records are editorials and commentaries. Since these works represent substantive contributions to the literature, and provide information about the venues and authors that are actively contributing to the “data science education” discourse, they were retained in the coreDSEworks dataset. However, because they works do not include references, only 280 records directly impact the construction of the reference works dataset and the reference co-citation network that are described in the following sections.

### 2.2. Extracting and Cleaning DSE Reference Works

Next, I construct a new dataset refWorks to represent the full set of foundational works from which the "data science education" literature represented by coreDSEworks draws. This is done by extracting the full reference lists of each coreDSEworks paper.

```{r}
#| label: extract-reference-works
#| warnings: false

refWorks <- as.data.frame(
  citations(coreDSEworks, field = "article", sep = ";")$Cited)
```

As noted by [@mike2023], this process is not straightforward—especially when looking at publications from multiple different fields. The reference lists included in Scopus and WoS databases are text-only, and the style guides that are used across the publications engaged in data science education (including but not limited to, the Association for Computing Machinery, the American Psychological Association, and the Institute for Electrical and Electronics Engineers) use quite different reference formats. Therefore, the process of cleaning references to ensure duplicate records are accurately matched and properly counted is not trivial. This is especially true for highly visible works that are cited across multiple formats and are therefore more likely to shape our understanding of the field. Consider the list of records below, most (but not all) of which represent the same National Academies' [-@medicine2018] report *Data Science for Undergraduates: Opportunities and Options* listed below. Here, data wrangling means consolidating all duplicate records while preserving meaningful distinctions (such as between the *Data Science for Undergraduates* report and Adhikari et al's [-@adhikari2021] paper, which appears in the list below because it also features "Data Science for Undergraduates" in its title).

```{r}
#| label: demo-duplicates
#| output: false

showabit <- refWorks %>% filter( CR %like% "DATA SCIENCE FOR UNDERGRADUATES" ) %>% head(20)
# datatable(showabit, 
#   rownames=FALSE,
#   options=list(pageLength=20),
#   style='bootstrap',
#   class='table-condensed small table-striped'
#   )
```

If records such as the ones above are not properly consolidated, duplicate scholarly works would be represented in the network as several isolated papers, each with only marginal impact on the field as a whole. To address this problem of duplicate records and ensure that the resulting reference co-citation network is accurate, I use a combination of methods including removal of special characters, automated text matching, and a manual dictionary of duplicate records screened by author and year. Each text reference that is identified as a duplicate is mapped to a single parent format, turning refWorks into a lookup table.

```{r}
#| label: generate-lookup-table
#| output: false

source("scripts/clean_refs.R")
charExcludeList <- '[\r\n\\:\\(\\)+\\?\\|\\"\\“\\”\\,\'\\`\\‘\\.\\*\\’]'
refWorks$CR <- gsub(charExcludeList,'',refWorks$CR) # the original cited works

refWorks$correctedCR <- ""
refWorks$freqAgg <- refWorks$Freq

refWorks <- cleanSpecialChars(refWorks) 
refWorks <- cleanManualDuplicates(refWorks) 
refWorks <- autoMatch(refWorks,.75)
```

The refWorks lookup table is then used to replace all versions of any duplicated references in the text references field of the original coreDSEworks dataframe with the corrected "parent" version of the reference. This ensures that when the bibliometric analysis functions are applied to the coreDSEworks dataset (such as in the construction of the reference network and associated node measures in Section , all references will be appropriately consolidated in .

```{r}
#| label: tally-corrected-refs-in-coreDSEworks
#| output: false

# Replace refs lists in the core works datatable with cleaned refs
coreDSEworks <- rewriteCleanRefs(coreDSEworks,charExcludeList)

# update frequencies given found matches in coreDSEworks
refWorks <- correctFrequenciesCited(refWorks,coreDSEworks)
```

After consolidating citation counts across duplicate records in this way, the relative positions of different cited reference works changes substantially. Tab 3 of Fig 2 features the top 100 records in the lookup table with corrected citation counts, again ordered by frequency of citations. The differences between the original refWorks table and the corrected table demonstrate the importance of such records consolidation; the [-@medicine2018] *Data Science for Undergraduates* reference that was originally listed as the most frequently referenced citation is superseded by DeVeaux et al's [-@deveaux2017] curriculum guidelines. Similarly, several other works in the original top 10 list change position or are even replaced by others.

```{r}
#| label: show-corrected-refs

# datatable(refWorks[c(3,5)] %>% arrange(desc(refWorks$freqCit)) %>% head(20), 
#   rownames=FALSE,
#   options=list(pageLength=5),
#   style='bootstrap',
#   class='table-condensed small table-striped'
# )
```

#### 2.3 Indexing Between Core DSE Publications and Reference Work

Finally, to form the "meso" level of analysis that connects current themes in data science education to their foundations within different reference literatures, it is necessary to map back and forth between all three of the coreDSEworks, refWorks, and bibNetwork datasets. To do this, I create shortnames that function as an index. Shortnames follow the format used by the bibliometrix analysis package when it generates the reference co-citation network: author last name, author first initial(s), year of publication. This allows me to map insights from analysis of `bibNetwork`, which only identifies nodes by shortname, back to their more complete corresponding reference records in `refWorks`. It also allows me to identify which `coreDSEworks` records demonstrate particular structural relationships to the underlying reference networks. For example, in Section I use `bibNetwork` shortnames to identify which `coreDSEworks` draw predominantly from only one of the clusters identified in the reference work network analysis, versus which draw in a more balanced way from all three clusters.

```{r}
#| label: generate-shortnames

source("scripts/shortnames.R")
# create shortnames and add them as a new ref list to coreDSEworks
refWorks <- refShortNames(refWorks)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)
```

In cases where more than one reference exists from the same first author in the same year, shortnames are appended with a number, by descending citation frequency. This, too, replicates shortnames as they appear in the `refNetwork`. For example, below are shortnames for multiple distinct reference works in 2018, for which R Biehler served as first author:

```{r}
#| label: illustrate-shortnames

biehler <- refWorks %>% filter(shortname %like% "biehler r 2018")

# datatable(biehler[c(1,5,6)] %>%
#             filter(freqCit > 0) %>%
#             arrange(desc(freqCit)), 
#             rownames=FALSE,
#             options=list(pageLength=5),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

## 3. Constructing the DSE Reference Co-Citation Network

Finally, I use the `biblioNetwork` function within the R `bibliometrix` package. This function is applied to the *cleaned* reference records of `coreDSEworks`; that is, the duplicated records that were originally extracted from the reference lists have been replaced with the cleaned, consolidated records and will be appropriately aggregated in the construction of the final reference document co-citation network. Only references that are cited at least 3 times are included in the analysis, to reduce the influence of isolated papers in favor of identifying repeated trends in the literature.

```{r}
#| label: generate-ref-net
# build co-citation network of DSE cited works
refMatrix <- biblioNetwork(coreDSEworks, analysis = "co-citation",
                           network = "references", sep = "; ")
```

Fig 3 features a visualization of the reference co-citation network of all papers that are cited at by at least 3 distinct core DSE works. In both representations, three distinct clusters can be identified: a green cluster to the left of both \[XXX\]

```{r}
#| label: visualize-ref-net

inclusion.cite.count = 2
cutoff = as.integer(count(refWorks %>% 
                            filter(freqCit>inclusion.cite.count)))
refNet=networkPlot(refMatrix, n = cutoff,
                   Title = "Co-Citation Network of Top DSE Reference Works",
                   size.cex=TRUE, size=15, remove.multiple=FALSE,
                   remove.isolates = TRUE, labelsize=.7, edgesize = 5,
                   edges.min=0, type = "fruchterman", cluster = "louvain",
                   community.repulsion = .04)
# louvain clustering seeks community membership

# we created shortnames for all duplicates, but refNet will 
# only create shortnames for items that are cited at least the 
# inclusion.cite.count number of times. Let's update to that.
refWorks <- refShortNames(refWorks,inclusion.cite.count)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)
```

While these two visualization formats are intended to highlight different features of the network structure, both identify the same three main clusters. Consistent with research on bibliometric citation network analysis (e.g. XXX), I conceptualize of these three clusters as representing distinct intellectual communities that together form the foundations of the Data Science Education literature. The remainder of this paper examines the nature of these communities and the similarities and differences among them.

### 3.1 Structural Foundations of Data Science Education

In the remainder of the results section, I first present an analysis of the structure and content of the reference network itself, to better understand the scholarly foundations of "Data Science Education". I explore the most highly cited "broker works" of this network---that is, the papers that connect across the otherwise distinct clusters in the network--- as well as the most highly cited "hub works" specific to each of the three clusters, to better understand which references distinguish these clusters from one another.

#### 3.1.1 DSE Broker Works

In network science, a *broker* describes a node in a network that connects otherwise distinct communities. These nodes are characterized by high betweenness centrality measures. When applied to bibliographic networks, broker works reflect papers that are referenced alongside papers that belong to otherwise distinct reference clusters. This can signal higher visibility or relevance of these works as bridges across scholarly communities.

The top ten broker works as identified by betweenness centrality are featured in Fig X. This collection includes well-known articles that work to define the nature of data science as a field [@conway2010][@cleveland2001][@donoho2017][@berman2018], and that present frameworks and guidelines to ensure that new data science training programs support the development of key skills that students involved in data fields should learn, and how they intersect with industry [@demchenko2016;\@irizarry2020][@nationalacademiesofsciencesengineeringandmedicine2018][@deveaux2017][@anderson2014].

```{r}
#| label: pull-top-brokers

# select the most "between" reference works. Show the top ten
# and include the top 50
refBrokers <- refNet[["cluster_res"]] %>% 
  arrange(desc(btw_centrality)) %>%
  head(50)

# use shortnames to identify the full citation for each
# reference broker work from the refWorks data frame
refBrokers$vertex <- paste0(
  word(refBrokers$vertex,1), " ",
  str_sub(word(refBrokers$vertex,2),1,1), " ",
  word(refBrokers$vertex,3))

# refNet is shortnaming these with appendix; manually fix for the join
refBrokers$vertex[refBrokers$vertex=="demchenko y 2016"] <- "demchenko y 2016-1"
refBrokers$vertex[refBrokers$vertex=="anderson p 2014-1"] <- "anderson p 2014"

relevantRefs <- refWorks %>% 
  filter(shortname %in% refBrokers$vertex) %>% 
  filter(freqCit > inclusion.cite.count) %>% 
  arrange(desc(freqCit))

# datatable(left_join(refBrokers, relevantRefs, by=c("vertex"="shortname") )[c(8,10)],
#             rownames=FALSE,
#             options=list(pageLength=10),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

As is evident in the table, the most frequently cited "broker" reference works are [@deveaux2017; @medicine2018; @cleveland2001]

In general, betweenness centrality is expected to reproduce citqtion frequency. However, while many of the broker works are also frequently cited, many of the most frequently cited works do not appear in the top ten broker works, and some less frequently cited works do. For example, [@dasgupta2017] is only cite 6 times but is identified as a broker work. This means that because though it is less frequently cited, it has been cited by works that otherwise draw heavily from one one of the three smaller networked communites we describe in the following section. This reinforces the isolated nature of the three communities.

## 4. The Three Worlds of Data Science Education

While broker works establish what different scholarly communities cite in common, identifying "hub" works that are only cited frequently alongside papers in each cluster can help highlight what distinguishes one scholarly community from another. Below, I work to characterize these communities by identifying, for each, a number of key characteristics including (1)

```{r}
#| label: prepare-to-extract-clusters

y <- refNet[["cluster_res"]]$btw_centrality
y[y==0] <- NA

# set the cutoff to lowest 75th percentile in terms of betweenness centrality
btw_cutoff <- quantile(y,c(.75),na.rm=TRUE)

referenceClusterAuthors <- refNet[["cluster_res"]] %>%
  # restrict this to only authors of papers that are not very connected
  # outside of their specific cluster
  #filter( btw_centrality < mean(refNet[["cluster_res"]]$btw_centrality) ) %>%
  filter( btw_centrality < btw_cutoff ) %>%
  group_by(cluster) %>%
  summarize(authors = list(
    paste(
      word(vertex,1),  # first word (last name)
      str_sub(word(vertex,2),1,1),     # second word (first initial)
      word(vertex,3) )
    )
  )

getClusterHub <- function(i) {
  clusterLookup <- referenceClusterAuthors$authors[[i]]
  return( refWorks %>%
    filter( !is.na( shortname ) ) %>% 
    filter( shortname %in% clusterLookup ) %>%
    filter( freqCit > 0 ) %>%
    arrange( desc(freqCit) ) )
}

# add $refInfo as quick lookup for what cluster the refs belong to
for( i in 1:nrow(coreDSEworks) ) {
  coreDSEworks$refInfo[i] <- refNet[["cluster_res"]] %>% 
       filter( str_detect(vertex, coreDSEworks$shortnameRefs[i]) == TRUE ) %>% 
    select(cluster)
}

getHeavyCitingWorks <- function(coreDSEworks,n,range="[1-3]") {
  # filter to look at works citing at least 5 DSE refWorks
  coreCitingWorks <- coreDSEworks %>% 
    filter( str_count(coreDSEworks$refInfo,range) > 5 )
  
  # then only include those that have >75% reWorks from cluster n
  coreCitingWorks <- coreCitingWorks %>% 
    filter( str_count(coreCitingWorks$refInfo,as.character(n))
            /str_count(coreCitingWorks$refInfo,range) > .75 )
  
  return( coreCitingWorks )
}

```

### 4.1 World 1: Data Science Undergraduate Programs

One community is comprised of works that speak to curriculum development and strategies to introduce data science to specialists at the postsecondary level. The majority of publications are from journals that focus on Statistics and Information Sciences. It also includes papers focused on active learning techniques (CITE), and specific tools used for data work (CITE). Methodological papers include

```{r}
#| label: see-cluster-hub-1

# datatable(getClusterHub(1)[c(3,5)], 
#             rownames=FALSE,
#             options=list(pageLength=5),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

#### 4.1.1 Key Characteristics of World 1

In terms of audience and content,emphasis is on curriculum and pedgogy for undergraduate level.

While there is no clear publication venue that is dominant within this collection of papers, the journals and conferences where this work appears focus on statistics education (JSDSE, TS), information technologies (Education and Information Technologies, Data Technologies and Applications, Proceedings of the Association for Infomration Science and Technology), and library science (IFLA Journal-International Federation of Library Associations, Journal of Academic Librarianship, Journal of Education for Library and Information Sciences). One focused on education (Education Sciences).

In terms of pedagogy and methodology,

#### 4.1.2 Works that Cite World 1

```{r}
#| label: find-citing-core-works-cluster1
#| output: false

coreCitingWorks1 <- getHeavyCitingWorks(coreDSEworks,1)

#datatable(coreCitingWorks1[c(4,6)],
#            rownames=FALSE,
#            options=list(pageLength=5),
#            style='bootstrap',
#            class='table-condensed small table-striped'
#            )
```

### 4.2 World 2: K-12 Students and the Learning Sciences

The second community is comprised of paper that focus on introducing data literacy and data science skills to non-majors, including at the university and pre-college levels.

```{r}
#| label: see-cluster-hub-2

# datatable(getClusterHub(2)[c(3,5)], 
#             rownames=FALSE,
#             options=list(pageLength=5),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

#### 4.2.1 Key Characteristics of World 2

In terms of audience and content,

In terms of pedagogy and methodology,

#### 4.2.2 Works that Cite World 2

```{r}

#| label: find-citing-core-works-cluster2
#| output: false

coreCitingWorks2 <- getHeavyCitingWorks(coreDSEworks,2)

# datatable(coreCitingWorks2[c(4,6)],
#             rownames=FALSE,
#             options=list(pageLength=5),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

### 4.3 World 3: Computational Approaches to Data for Non-Majors

The third community is comprised of researchers who are focused on introducing data science at the K-12 level, with a primary focus on the computational aspects of data science.

```{r}
#| label: see-cluster-hub-3

# datatable(getClusterHub(3)[c(3,5)], 
#             rownames=FALSE,
#             options=list(pageLength=5),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

#### 4.3.1 Key Characteristics of World 3

In terms of audience and content,

In terms of pedagogy and methodology,

#### 4.3.2 Works that Cite World 3

```{r}
#| label: find-citing-core-works-cluster3
#| output: false

coreCitingWorks3 <- getHeavyCitingWorks(coreDSEworks,3)

# datatable(coreCitingWorks3[c(4,6)],
#             rownames=FALSE,
#             options=list(pageLength=5),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

### 4.4 Works that Cite Across Communities

Finally, to better understand the relationship between the reference co-citation network itself and the core Data Science Education literature, I present a deeper analysis of *how* core DSE works draw from these different clusters of literature. I present an analysis of recently published Data Science Education papers that draw heavily from While the reference co-citation network represents the scholarly foundations of what currently constitutes the "Data Science Education" literature, many of the works in this network predate the emergence of the field, and many deal with proximally or even more distally related topics (e.g. Statistics Education, Learning Theory, Education Research Methodologies).

```{r}
#| label: find-bridging-works
#| warning: false

bridges <- coreDSEworks %>% 
  filter( str_count(coreDSEworks$refInfo,"[1-3]") > 5 )
  
bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("1"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("2"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("3"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

# datatable(bridges[c(5,4,6)],
#             rownames=FALSE,
#             options=list(pageLength=5),
#             style='bootstrap',
#             class='table-condensed small table-striped'
#             )
```

## 5. Discussion

This analysis also highlights a few shared areas of concern across all areas. One, for example, concerns issues of ethics in the teaching and learning of data science. This appears frequently in broker works (e.g., XXX) as well as in popular works within each community (xxx). While not the focus of the current analysis, it is also worth noting that a collection of more popular academic books including *Race After Technology*, *Weapons of Math Destruction* [-@oneil2016]*, Data Feminism*, and *Algorithms of Oppression* [-@noble2018]

This analysis also suggests that the emerging data science education field would benefit from literature search methods that span different publication venues. For example, both Cluster 2 (Education and Learning Sciences) and Cluster 3 (Data Science for Non-Majors) feature several reports on the design and enactment of K-12 data science learning environments. However, these reports appear in notably different publication fora, with the former group of work appearing primarily in Learning Sciences and Education journals, and the latter appearing primarily in conference proceedings, particularly those associated with the computer science field.

Bridging Toward More Coherent Data Science Education Trajectories

XXX

Limitations. Still a small field, and working with small numbers. Some of the relationships observed here may be driven by one or a few paprs (e.g., certain research groups whose output reproduces particular citation patterns across papers). Also important to recognize the impact of time, older papers have more time to be picked up and cited than new papers. Good for understanding the foundations so far, but not necessarily for predicting how these fields will develop moving forward.

## 6. References
