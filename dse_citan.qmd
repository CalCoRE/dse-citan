---
title: "dse-citan"
author: "removed for review"
format: 
  html:
    toc: true
    code-fold: true
    code-summary: "Show the code"
    embed-resources: true
    css: "style.css"
editor: visual
bibliography: references.bib
csl: apa.csl
---

# The Many Worlds of "Data Science Education"

As readers of HDSR know well, there is wide diversity in who is involved in data science education research and how it is conceptualized (Data Science Education, n.d.). Navigating this landscape can be challenging, especially for those who are just entering the field or who seek complementary insights from other related domains. Different academic communities may use different terminology, or they may hold different conceptualizations for the same key terms, "talking past" one another. Publication practices and norms also differ across fields, making it harder for researchers to find relevant work. Meanwhile, there are still only a few venues (including the Harvard Data Science Review, the Journal of Statistics and Data Science Education, Teaching Statistics) that specifically advertise data science education as an area of focus (Hazzan & Mike, 2021).

Despite these ongoing challenges, there is growing evidence that it is time to take stock and build common understandings of data science education as a field in its own right. This report contributes to those efforts by presenting a mixed-methods investigation of 287 papers that explicitly identify themselves in their title, keywords, or abstract as concerned with “data science education,” as well as of the 7,000+ reference works that, together, form the de facto foundations of data science education scholarship. These reference works are extracted from the focal set of “data science education” papers to construct a co-citation network that highlights the structure of the knowledge base(s) that are informing data science education as an emerging field.

Analysis of the reference co-citation network suggests that while there are several shared (but not-so-shared) "broker" references that are broadly cited within the emerging data science education literature, current data science education scholarship is built atop three distinctive and conceptually coherent, but rather isolated clusters of reference work. I characterize each cluster with attention to the audiences, themes, pedagogy, and methodologies emphasized, and explore the nature of recent data science education papers that draw from each cluster. I then examine areas of agreement and divergence across the clusters. All three clusters of literature include attention to student-centered pedagogies, case-based methodologies that highlight student experience, and ethics and diversity. However, there are notable areas of divergence, especially between undergraduate and K-12 data science education efforts, between data science majors versus non-majors, and between K-12 data science initiatives emerging from different groups.

My goal is to raise awareness of the diversity of communities working on data science education, and to encourage deeper engagement with literature and researchers across these communities. In that spirit, this report is accompanied by an interactive open-source Quarto document that readers can use to peruse the reference works that make up the many worlds of data science education. Understanding what we can learn from each other can support stronger, more coherent trajectories for future data science students, as well as for all students who will find themselves navigating a data-filled world.

## 1. Why Map Data Science Education Scholarship?

As data science education emerges as a discipline in its own right (Finzer, 2013; Lee et al., 2021; Mike et al., 2023; National Academies of Sciences, Engineering, and Medicine, 2018, 2023), still little is known about its core scholarly foundations. This is not surprising, given the rapid evolution of the field of data science and the variety of academic communities that are involved in its development. In many ways, data science education is even more interdisciplinary than data science as a field. Studying the teaching and learning of data science not only involves the content that is being taught, but also requires attention to theories of learning, educational infrastructures, appropriate social science methodologies, and curricular frameworks. There are also multiple established literatures that address some important conceptual foundations of data science (e.g. statistics education, Ben-Zvi et al., 2018; Nolan & Temple Lang, 2010; and computing education, Fincher & Robins, 2019) and of related topics (e.g. scientific visualization, Edelson & Gordin, 1998; data literacies, Pangrazio & Selwyn, 2019).

Despite these complexities, data science education research and curriculum development races ahead not only at universities but also in K-12 (Weiland & Engledowl, 2022), at community colleges (Baumer & Horton, 2023), and in the professional development of teachers (Hudson et al., n.d.). It is important to understand how different research communities are approaching data science education, what these communities might learn from each other and from their histories of scholarship, and what this all might mean for the different types of "data science education" students might experience across levels and institutions.

### 1.1. The Interdisciplinarity of Data Science Education

The earliest programs in data science were born from a variety of departments including statistics, computer science, business analytics, information and library sciences, each with distinctive emphases and approaches. One of the clearest differences in approach to data science education approaches has been between statistics and computer science. A recent scoping review of data science education literature by Msweli and colleagues (2023) found that most papers they identified in their search did not explicitly name data science, but rather computer science or statistics, as the home discipline of their work. A pair of workshops offered in 2019 at the ACM's Special Interest Group in Computer Science Education (Cetinkaya-Rundel, Danyluk, et al., 2019) and at the Joint Statistical Meetings (Cetinkaya-Rundel, Posner, et al., 2019), respectively, highlight efforts by both communities to foster collaboration between disciplines.

In just the past few years, we have learned more about potential areas of specialization within the published products of data science education. In a recent review, Mike and colleagues (2023) leveraged k-means clustering techniques to classify a collection of over 1,000 papers selected on the intersection of the phrase “data science” with education-related terms such as “education”, “teaching”, and “curriculum” to identify core areas of focus for this emerging field. They identified five key themes: curriculum; pedagogy; STEM skills; domain adaptation; and social aspects. While the themes were not traced to disciplinary communities of origin, there is some suggestion of domain specialization within the emergent themes suggested by the cluster analysis. For example, within a cluster called "STEM skills", two clusters (3.1 – Statistics education and 3.5 – Statistics for data science) were identified as connected to statistics, and three (3.2 – Computer science for data science; 3.3 – Cloud computing in data science education; and 3.4 – Data engineering) were identified as connected to computer science.

More signs of scholarly specialization emerge even within narrower focal areas of data science education research. Rosenberg and Jones (2024) present vignettes illustrating substantially different visions of what constitutes "data science education" at the K-12 level. The vignettes were derived from an analysis of three recent journal special issues (a total of 28 papers and their shared references) dedicated to the topic. They found that despite their shared topical focus, each special issue reflected distinct orientations toward the field, emphasizing the material, personal, or disciplinary aspects of data science. Rosenberg and Jones highlighted the different levels of cohesiveness in what literature was cited by papers within versus across special issues, as well as a relative lack of cohesiveness in what literature was cited by scholars focused on K-12 versus undergraduate education.

All this suggests that there may be relatively independently developing communities of data science education scholarship. These communities are likely attending to different themes, audiences, and approaches of the sort identified in Mike et al (2023); and, they are likely drawing from somewhat different foundational literatures as highlighted by Rosenberg & Jones (2024). One goal of the current work is to offer a "meso" level examination that works to map broad emerging themes to their respective intellectual foundations.

### 1.2. Bibliometric Mapping to Understand "Voluminous, Fragmented" Fields

Science mapping is a form of bibliometric analysis that leverages metadata from published works to characterize the structure of scholarly literatures. It is especially useful for understanding fields that are developing rapidly and that are "voluminous and fragmented" (Aria & Cuccurullo, 2017, p. 959). Here I rely on co-citation analysis, one of the most popular and validated bibliometric methods (Zupic & Čater, 2015). Co-citation analysis measures how often certain entities (such as authors, institutions, journals, or documents) appear together in the reference lists of a focal set of papers, assessing entities that appear together more frequently as more conceptually proximal.

Here, I focus specifically on a co-citation analysis of the papers that are referenced by a set of focal published works that claim to focus on “data science education.” The collection of papers can be understood as the "knowledge base" that informs data science education, and their relative proximity and other structural features can be understood as characterizing the “intellectual structure” of the field (Zupic & Čater, 2015, pp. 11–12).

To supplement the reference co-citation network analysis with deeper exploration of the conceptual implications of these knowledge bases and structures, I also leverage qualitative content analysis and bibliographic coupling methods. Qualitative content analysis will focus on identifying the primary audience, content, pedagogical approaches, and methodological frameworks employed within each foundational cluster, to the extent possible. Bibliographic coupling allows deeper exploration of what are the *products* of different knowledge bases, by identifying papers that draw heavily from specific clusters of foundational literature. Following the recommendation in Zupic and Čater (2015), I limit bibliographic coupling analysis of intellectual clusters to only the most recent 5 years of publications.

Haustein and Larivière (2015) emphasize the dangers of an over-reliance on bibliometric methods to describe disciplines or scholarly impact. It is important to recognize bibliometric signals as *indicators*, not direct measures of impact or significance. Additionally, given that different disciplines have different publication norms, direct comparisons of indicators such as publication count or citation frequency across communities is not appropriate. This analysis is directed toward structural features of co-citation, rather than on specific authors or institutions, and with less emphasis on citation frequency. The primary goal of this work is to locate potential collaborators and complementary communities of scholars, rather than to make claims about the relative impact of scholarship.

## 2. Constructing the Bibliographic Datasets

This research leverages the R `bibliometrix` package [@aria2017] for constructing, analyzing, and visualizing bibliographic records. I use the `dplyr` package for data handling [@wickham2023], and the `stringr` and `textTools` packages to process and compare scholarly reference records. The `DT` package [@dt:awr2024] is used to generate interactive data displays.

```{r}
#| label: load-packages-and-scripts
#| warning: false

# for the analysis
library(bibliometrix)

# for working with data
library(dplyr)
library(stringr)
library(textTools)

# for a pretty document
library(DT)
```

Consistent with the bibliometric co-citation methods described in Section 1.2, this analysis focuses on three interrelated datasets (also illustrated in [Figure 1](#data-sources)).

-   A collection called `coreDSEworks` describes a core set of 287 scholarly works selected to represent the core, emerging data science education literature. These are indexed academic publications that feature the full phrase "data science education" in the title, abstract, or keywords.

-   A second, much larger collection of scholarly works called `refWorks` represents \[xxx\] distinct papers that are cited by, and are therefore constitute the *de facto* intellectual foundations of, the emerging data science education literature. This dataset is constructed by extracting references from the bibliographies of each record in `coreDSEworks`. Since papers in `coreDSEworks` cite one another, many appear in both datasets.

-   Finally, `bibNetwork` describes a weighted document co-citation network of `refWorks`. It represents each record in `refWorks` as a node in the network. The more frequently a given reference document is cited by the core works, the higher the weight of the corresponding node in `bibNetwork`. Two nodes in the network are connected by an edge when both works appear in the reference list of the same core document (A, B, C, etc.). The more frequently two nodes appear together in the reference lists of core documents, the heavier the weight of the corresponding edge.

![Figure 1. Three key data frames: coreDSEworks, refWorks that are cited in the coreDSEworks, and the bibNetwork that represents co-citation patterns of refWorks.](dse_citan_files/datasources.png){#data-sources width="600"}

### 2.1 Identifying Core Data Science Education Publications

To conduct this review, I selected an intentionally narrow, but relevant and well-specified set of initial works to form the “core” set of papers meant to represent the field: publications that are indexed in either Scopus or Clarivate Analytics Web of Science ("WoS") and that include the specific full phrase “data science education” in the title, abstract, or keywords. As of Dec 9, 2024, this query yielded a total of 287 records after screening to remove duplicates and inappropriate records. Records deemed inappropriate included one correction statement (for which the corrected report remained included), one retraction statement and the corresponding retracted article, four full conference review records, and one full poster session review record. For each of the four excluded conference proceedings records, I confirmed that the more specific corresponding record included in the full review was included instead. For the excluded poster session review record, corresponding poster records were not available. None of the five review records that were removed included cited reference information. [Figure 2](#prisma-fig) features a PRISMA diagram describing the construction of the `coreDSEworks` corpus.

![PRISMA diagram describing construction of the coreDSEworks corpus](dse_citan_files/prisma.png){#prisma-fig width="600"}

```{r}
#| label: get-core-works
#| output: false

source("scripts/read_works.R")
coreDSEworks <- getCoreDSEWorks()
```

While the focus of this paper is not on the core works themselves, it is useful to briefly review some key descriptive characteristics of the coreDSEworks collection to determine its validity for this analysis. The histogram featured in Figure 3 reflects the nascent nature of this area of study, with the first publication appearing in 2012 and relatively steady growth since then.

```{r}
#| label: show-pub-years

hist(coreDSEworks$PY)
```

The titles, authors, publication venues, and publication years of each `coreDSEworks` record is presented in randomized order below:

```{r}
#| label: display-core-works

datatable(coreDSEworks[
  sample(1:nrow(coreDSEworks)), 
  c(4,1,6,5)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

Of the 287 publication records that are not excluded from the coreDSEworks corpus, seven do not include information about cited references. Manual inspection reveals that these records are editorials and commentaries. Since these works represent substantive contributions to the literature, and provide information about the venues and authors that are actively contributing to the “data science education” discourse, they were retained in the coreDSEworks dataset. However, because they works do not include references, only 280 records directly impact the construction of the reference works dataset and the reference co-citation network that are described in the following sections.

### 2.2. Extracting and Cleaning DSE Reference Works

Next, I construct a new dataset refWorks to represent the full set of foundational works from which the "data science education" literature represented by coreDSEworks draws. This is done by extracting the full reference lists of each coreDSEworks paper.

```{r}
#| label: extract-reference-works
#| warnings: false

refWorks <- as.data.frame(
  citations(coreDSEworks, field = "article", sep = ";")$Cited)
```

As noted by [@mike2023], this process is not straightforward—especially when looking at publications from multiple different fields. The reference lists included in Scopus and WoS databases are text-only, and the style guides that are used across the publications engaged in data science education (including but not limited to, the Association for Computing Machinery, the American Psychological Association, and the Institute for Electrical and Electronics Engineers) use quite different reference formats. Therefore, the process of cleaning references to ensure duplicate records are accurately matched and properly counted is not trivial. This is especially true for highly visible works that are cited across multiple formats and are therefore more likely to shape our understanding of the field. Consider the list of records below, most (but not all) of which represent the same National Academies' [-@medicine2018] report *Data Science for Undergraduates: Opportunities and Options* listed below. Here, data wrangling means consolidating all duplicate records while preserving meaningful distinctions (such as between the *Data Science for Undergraduates* report and Adhikari et al's [-@adhikari2021] paper, which appears in the list below because it also features "Data Science for Undergraduates" in its title).

```{r}
#| label: demo-duplicates
#| output: false

showabit <- refWorks %>% filter( CR %like% "DATA SCIENCE FOR UNDERGRADUATES" ) %>% head(20)
datatable(showabit,
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

If records such as the ones above are not properly consolidated, duplicate scholarly works would be represented in the network as several isolated papers, each with only marginal impact on the field as a whole. To address this problem of duplicate records and ensure that the resulting reference co-citation network is accurate, I use a combination of methods including removal of special characters, automated text matching, and a manual dictionary of duplicate records screened by author and year. Each text reference that is identified as a duplicate is mapped to a single parent format, turning refWorks into a lookup table.

```{r}
#| label: generate-lookup-table
#| output: false

source("scripts/clean_refs.R")
charExcludeList <- '[\r\n\\:\\(\\)+\\?\\|\\"\\“\\”\\,\'\\`\\‘\\.\\*\\’]'
refWorks$CR <- gsub(charExcludeList,'',refWorks$CR) # the original cited works

refWorks$correctedCR <- ""
refWorks$freqAgg <- refWorks$Freq

refWorks <- cleanSpecialChars(refWorks) 
refWorks <- cleanManualDuplicates(refWorks) 
refWorks <- autoMatch(refWorks,.75)
```

The refWorks lookup table is then used to replace all versions of any duplicated references in the text references field of the original coreDSEworks dataframe with the corrected "parent" version of the reference. This ensures that when the bibliometric analysis functions are applied to the coreDSEworks dataset (such as in the construction of the reference network and associated node measures in Section , all references will be appropriately consolidated in .

```{r}
#| label: tally-corrected-refs-in-coreDSEworks
#| output: false

# Replace refs lists in the core works datatable with cleaned refs
coreDSEworks <- rewriteCleanRefs(coreDSEworks,charExcludeList)

# update frequencies given found matches in coreDSEworks
refWorks <- correctFrequenciesCited(refWorks,coreDSEworks)
```

After consolidating citation counts across duplicate records in this way, the relative positions of different cited reference works changes substantially. Tab 3 of Fig 2 features the top 100 records in the lookup table with corrected citation counts, again ordered by frequency of citations. The differences between the original refWorks table and the corrected table demonstrate the importance of such records consolidation; the [-@medicine2018] *Data Science for Undergraduates* reference that was originally listed as the most frequently referenced citation is superseded by DeVeaux et al's [-@deveaux2017] curriculum guidelines. Similarly, several other works in the original top 10 list change position or are even replaced by others.

```{r}
#| label: show-corrected-refs

datatable(refWorks[c(3,5)] %>% 
            arrange(desc(refWorks$freqCit)) %>% 
            head(100),
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

#### 2.3 Indexing Between Core DSE Publications and Reference Work

Finally, to form the "meso" level of analysis that connects current themes in data science education to their foundations within different reference literatures, it is necessary to map back and forth between all three of the coreDSEworks, refWorks, and bibNetwork datasets. To do this, I create shortnames that function as an index. Shortnames follow the format used by the bibliometrix analysis package when it generates the reference co-citation network: author last name, author first initial(s), year of publication. This allows me to map insights from analysis of `bibNetwork`, which only identifies nodes by shortname, back to their more complete corresponding reference records in `refWorks`. It also allows me to identify which `coreDSEworks` records demonstrate particular structural relationships to the underlying reference networks. For example, in Section I use `bibNetwork` shortnames to identify which `coreDSEworks` draw predominantly from only one of the clusters identified in the reference work network analysis, versus which draw in a more balanced way from all three clusters.

```{r}
#| label: generate-shortnames

source("scripts/shortnames.R")
# create shortnames and add them as a new ref list to coreDSEworks
refWorks <- refShortNames(refWorks)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)
```

In cases where more than one reference exists from the same first author in the same year, shortnames are appended with a number, by descending citation frequency. This, too, replicates shortnames as they appear in the `refNetwork`. For example, below are shortnames for multiple distinct reference works in 2018, for which R Biehler served as first author:

```{r}
#| label: illustrate-shortnames

biehler <- refWorks %>% filter(shortname %like% "biehler r 2018")

datatable(biehler[c(1,5,6)] %>%
            filter(freqCit > 0) %>%
            arrange(desc(freqCit)),
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

## 3. Constructing the DSE Reference Co-Citation Network

Finally, I use the `biblioNetwork` function within the R `bibliometrix` package. This function is applied to the *cleaned* reference records of `coreDSEworks`; that is, the duplicated records that were originally extracted from the reference lists have been replaced with the cleaned, consolidated records and will be appropriately aggregated in the construction of the final reference document co-citation network. Only references that are cited at least 3 times are included in the analysis, to reduce the influence of isolated papers in favor of identifying repeated trends in the literature.

```{r}
#| label: generate-ref-net
# build co-citation network of DSE cited works
refMatrix <- biblioNetwork(coreDSEworks, analysis = "co-citation",
                           network = "references", sep = "; ")
```

Fig 3 features a visualization of the reference co-citation network of all papers that are cited at by at least 3 distinct core DSE works. In both representations, three distinct clusters can be identified: a green cluster to the left of both \[XXX\]

```{r}
#| label: visualize-ref-net

inclusion.cite.count = 2
cutoff = as.integer(count(refWorks %>% 
                            filter(freqCit>inclusion.cite.count)))
refNet=networkPlot(refMatrix, n = cutoff,
                   Title = "Co-Citation Network of Top DSE Reference Works",
                   size.cex=TRUE, size=15, remove.multiple=FALSE,
                   remove.isolates = TRUE, labelsize=.7, edgesize = 5,
                   edges.min=0, type = "fruchterman", cluster = "louvain",
                   community.repulsion = .04)
# louvain clustering seeks community membership

# we created shortnames for all duplicates, but refNet will 
# only create shortnames for items that are cited at least the 
# inclusion.cite.count number of times. Let's update to that.
refWorks <- refShortNames(refWorks,inclusion.cite.count)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)
```

While these two visualization formats are intended to highlight different features of the network structure, both identify the same three main clusters. Consistent with research on bibliometric citation network analysis (e.g. XXX), I conceptualize of these three clusters as representing distinct intellectual communities that together form the foundations of the Data Science Education literature. The remainder of this paper examines the nature of these communities and the similarities and differences among them.

### 3.1 Structural Foundations of Data Science Education

In the remainder of the results section, I first present an analysis of the structure and content of the reference network itself, to better understand the scholarly foundations of "Data Science Education". I explore the most highly cited "broker works" of this network---that is, the papers that connect across the otherwise distinct clusters in the network--- as well as the most highly cited "hub works" specific to each of the three clusters, to better understand which references distinguish these clusters from one another.

#### 3.1.1 DSE Broker Works

In network science, a *broker* describes a node in a network that connects otherwise distinct communities. These nodes are characterized by high betweenness centrality measures. When applied to bibliographic networks, broker works reflect papers that are referenced alongside papers that belong to otherwise distinct reference clusters. This can signal higher visibility or relevance of these works as bridges across scholarly communities.

The top ten broker works as identified by betweenness centrality are featured in Fig X. This collection includes well-known articles that work to define the nature of data science as a field [@conway2010][@cleveland2001][@donoho2017][@berman2018], and that present frameworks and guidelines to ensure that new data science training programs support the development of key skills that students involved in data fields should learn, and how they intersect with industry [@demchenko2016;\@irizarry2020][@nationalacademiesofsciencesengineeringandmedicine2018][@deveaux2017][@anderson2014].

```{r}
#| label: pull-top-brokers

# select the most "between" reference works. Show the top ten
# and include the top 50
refBrokers <- refNet[["cluster_res"]] %>% 
  arrange(desc(btw_centrality)) %>%
  head(50)

# use shortnames to identify the full citation for each
# reference broker work from the refWorks data frame
refBrokers$vertex <- paste0(
  word(refBrokers$vertex,1), " ",
  str_sub(word(refBrokers$vertex,2),1,1), " ",
  word(refBrokers$vertex,3))

# refNet is shortnaming these with appendix; manually fix for the join
refBrokers$vertex[refBrokers$vertex=="demchenko y 2016"] <- "demchenko y 2016-1"
refBrokers$vertex[refBrokers$vertex=="anderson p 2014-1"] <- "anderson p 2014"

relevantRefs <- refWorks %>% 
  filter(shortname %in% refBrokers$vertex) %>% 
  filter(freqCit > inclusion.cite.count) %>% 
  arrange(desc(freqCit))

datatable(left_join(refBrokers, relevantRefs, by=c("vertex"="shortname") )[c(8,10)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

As is evident in the table, the most frequently cited "broker" reference works are [@deveaux2017; @medicine2018; @cleveland2001]

In general, betweenness centrality is expected to reproduce citqtion frequency. However, while many of the broker works are also frequently cited, many of the most frequently cited works do not appear in the top ten broker works, and some less frequently cited works do. For example, [@dasgupta2017] is only cite 6 times but is identified as a broker work. This means that because though it is less frequently cited, it has been cited by works that otherwise draw heavily from one one of the three smaller networked communites we describe in the following section. This reinforces the isolated nature of the three communities.

## 4. Characterizing the Three Foundational Literatures of Data Science Education

While broker works establish what different scholarly communities cite in common, identifying "hub" works that are only cited frequently alongside papers in each cluster can help highlight what distinguishes one scholarly community from another. Below, I work to characterize these communities by identifying, for each, a number of key characteristics including (1)

```{r}
#| label: prepare-to-extract-clusters

y <- refNet[["cluster_res"]]$btw_centrality
y[y==0] <- NA

# set the cutoff to lowest 80th percentile in terms of betweenness centrality
btw_cutoff <- quantile(y,c(.8),na.rm=TRUE)

referenceClusterAuthors <- refNet[["cluster_res"]] %>%
  # restrict this to only authors of papers that are not very connected
  # outside of their specific cluster
  #filter( btw_centrality < mean(refNet[["cluster_res"]]$btw_centrality) ) %>%
  filter( btw_centrality < btw_cutoff ) %>%
  group_by(cluster) %>%
  summarize(authors = list(
    paste(
      word(vertex,1),  # first word (last name)
      str_sub(word(vertex,2),1,1),     # second word (first initial)
      word(vertex,3) )
    )
  )

getClusterHub <- function(i) {
  clusterLookup <- referenceClusterAuthors$authors[[i]]
  return( refWorks %>%
    filter( !is.na( shortname ) ) %>% 
    filter( shortname %in% clusterLookup ) %>%
    filter( freqCit > 0 ) %>%
    arrange( desc(freqCit) ) )
}

# add $refInfo as quick lookup for what cluster the refs belong to
for( i in 1:nrow(coreDSEworks) ) {
  coreDSEworks$refInfo[i] <- refNet[["cluster_res"]] %>% 
       filter( str_detect(vertex, coreDSEworks$shortnameRefs[i]) == TRUE ) %>% 
    select(cluster)
}

getHeavyCitingWorks <- function(coreDSEworks,n,range="[1-3]") {
  # filter to look at works citing at least 5 DSE refWorks
  coreCitingWorks <- coreDSEworks %>% 
    filter( str_count(coreDSEworks$refInfo,range) > 5 )
  
  # then only include those that have >90% reWorks from cluster n
  coreCitingWorks <- coreCitingWorks %>% 
    filter( str_count(coreCitingWorks$refInfo,as.character(n))
            /str_count(coreCitingWorks$refInfo,range) > .8 )
  
  # filter out older than 5 years
  coreCitingWorks <- coreCitingWorks %>% 
    filter( coreCitingWorks$PY > 2019 )
  
  return( coreCitingWorks )
}

```

### 4.1 Data Science Undergraduate Programs

One community is comprised of works that speak to curriculum development and strategies to introduce data science to specialists at the postsecondary level. The majority of publications are from journals that focus on Statistics and Information Sciences. It also includes papers focused on active learning techniques (CITE), and specific tools used for data work (CITE). Methodological papers include

```{r}
#| label: see-cluster-hub-1

datatable(getClusterHub(1)[c(3,5)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

#### 4.1.1 Key Characteristics of Reference Works

In terms of audience and content,emphasis is on curriculum and pedgogy for undergraduate level.

While there is no clear publication venue that is dominant within this collection of papers, the journals and conferences where this work appears focus on statistics education (JSDSE, TS), information technologies (Education and Information Technologies, Data Technologies and Applications, Proceedings of the Association for Infomration Science and Technology), and library science (IFLA Journal-International Federation of Library Associations, Journal of Academic Librarianship, Journal of Education for Library and Information Sciences). One focused on education (Education Sciences).

In terms of pedagogy and methodology,

#### 4.1.2 Exemplar Citing Works

```{r}
#| label: find-citing-core-works-cluster1
#| output: false

coreCitingWorks1 <- getHeavyCitingWorks(coreDSEworks,1)

datatable(coreCitingWorks1[c(4,6)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

### 4.2 World 2: K-12 Students and the Learning Sciences

The second community is comprised of paper that focus on introducing data literacy and data science skills to non-majors, including at the university and pre-college levels.

```{r}
#| label: see-cluster-hub-2

datatable(getClusterHub(2)[c(3,5)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

#### 4.2.1 Key Characteristics of World 2

In terms of audience and content,

In terms of pedagogy and methodology,

#### 4.2.2 Works that Cite World 2

```{r}

#| label: find-citing-core-works-cluster2
#| output: false

coreCitingWorks2 <- getHeavyCitingWorks(coreDSEworks,2)

datatable(coreCitingWorks2[c(4,6)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

### 4.3 World 3: Computational Approaches to Data for Non-Majors

The third community is comprised of researchers who are focused on introducing data science at the K-12 level, with a primary focus on the computational aspects of data science.

```{r}
#| label: see-cluster-hub-3

datatable(getClusterHub(3)[c(3,5)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

#### 4.3.1 Key Characteristics of World 3

In terms of audience and content,

In terms of pedagogy and methodology,

#### 4.3.2 Works that Cite World 3

```{r}
#| label: find-citing-core-works-cluster3
#| output: false

coreCitingWorks3 <- getHeavyCitingWorks(coreDSEworks,3)

datatable(coreCitingWorks3[c(4,6)],
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

### 4.4 Works that Cite Across Communities

Finally, to better understand the relationship between the reference co-citation network itself and the core Data Science Education literature, I present a deeper analysis of *how* core DSE works draw from these different clusters of literature. I present an analysis of recently published Data Science Education papers that draw heavily from While the reference co-citation network represents the scholarly foundations of what currently constitutes the "Data Science Education" literature, many of the works in this network predate the emergence of the field, and many deal with proximally or even more distally related topics (e.g. Statistics Education, Learning Theory, Education Research Methodologies).

```{r}
#| label: find-bridging-works
#| warning: false

bridges <- coreDSEworks %>% 
  filter( str_count(coreDSEworks$refInfo,"[1-3]") > 5 )
  
bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("1"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("2"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

bridges <- bridges %>% 
  filter( str_count(bridges$refInfo,as.character("3"))
          /str_count(bridges$refInfo,"[1-3]") > .1 )

bridges <- bridges %>% filter(PY > 2019)

datatable(bridges[c(5,4,6)],
  rownames=FALSE,
  options=list(class='compact stripe')
)
```

## 5. Discussion

This analysis also highlights a few shared areas of concern across all areas. One, for example, concerns issues of ethics in the teaching and learning of data science. This appears frequently in broker works (e.g., XXX) as well as in popular works within each community (xxx). While not the focus of the current analysis, it is also worth noting that a collection of more popular academic books including *Race After Technology*, *Weapons of Math Destruction* [-@oneil2016]*, Data Feminism*, and *Algorithms of Oppression* [-@noble2018]

This analysis also suggests that the emerging data science education field would benefit from literature search methods that span different publication venues. For example, both Cluster 2 (Education and Learning Sciences) and Cluster 3 (Data Science for Non-Majors) feature several reports on the design and enactment of K-12 data science learning environments. However, these reports appear in notably different publication fora, with the former group of work appearing primarily in Learning Sciences and Education journals, and the latter appearing primarily in conference proceedings, particularly those associated with the computer science field.

Bridging Toward More Coherent Data Science Education Trajectories

XXX

Limitations. Still a small field, and working with small numbers. Some of the relationships observed here may be driven by one or a few paprs (e.g., certain research groups whose output reproduces particular citation patterns across papers). Also important to recognize the impact of time, older papers have more time to be picked up and cited than new papers. Good for understanding the foundations so far, but not necessarily for predicting how these fields will develop moving forward.

## 6. References
