---
title: "Mapping the Conceptual Foundation(s) of \"Data Science Education\""
author: "Michelle Hoda Wilkerson"
format: 
  html:
    toc: true
    code-fold: true
    code-summary: "Show the code"
    embed-resources: true
    css: "style.css"
editor: visual
bibliography: references.bib
csl: apa.csl
theme: minty

abstract: "The emerging field of data science education is broadly interdisciplinary, and related literature is distributed across a variety of outlets. Navigating this landscape can be challenging, especially for those who are just entering the field or who seek insights from multiple fields. This document contributes to a growing body of research that aims to characterize the emerging field of \"Data Science Education.\" It presents a reference co-citation analysis drawing from works that are cited by papers that explicitly identify themselves in their title, keywords, or abstract as concerned with “data science education”—thus representing the de facto foundations of this field."
---

::: callout-note
This is a Quarto-generated, regularly updated html version of Wilkerson, M. H. (2025). Mapping the Conceptual Foundation(s) of Data Science Education. Just Accepted in *Harvard Data Science Review*. <https://doi.org/10.1162/99608f92.9ac68105>

I will attempt to update this document to include the latest relevant publications in the bibliometric analysis roughly every 6 months. Naturally, this means findings evidenced in this document may change over time.

Have fun!! I'm super open to contributions at <https://github.com/CalCoRE/dse-citan>

Last update - August, 2025 by Michelle H. Wilkerson
:::

Data science sits at the intersection of many disciplines, ranging from statistics and computer science to a variety of application domains. It is not surprising, then, that there is also wide diversity in who is involved in data science *education*, and in how this emerging field is conceptualized [@datasci]. Navigating the landscape of data science education research can be challenging, especially for those who are just entering the field or who seek complementary insights from the various scholarly communities that are involved. Different academic communities may use different terminology, or they may hold different conceptualizations for the same key terms, "talking past" one another. Publication practices and norms also differ across fields, making it harder for researchers to find relevant work. Meanwhile, there are still only a few venues (including the *Harvard Data Science Review*, *Journal of Statistics and Data Science Education*, and *Teaching Statistics*) that specifically advertise data science education as an area of focus [@hazzan2021].

There is growing evidence that it is time to take stock and build common understandings of data science education as a field in its own right, despite (or perhaps because of) the difficulty in navigating this interdisciplinary scholarly landscape. This document seeks to clarify the scholarly communities that are shaping this emerging field by presenting a descriptive investigation of papers that explicitly identify themselves in their title, keywords, or abstract as concerned with “data science education,” as well as a scientific mapping analysis of the co-citation patterns of reference works that, together, form the *de facto* foundations of data science education scholarship. The goal is to highlight the "living" structure of the knowledge base(s) that are informing data science education as an emerging field.

My goal is to raise awareness of the diversity of communities working on data science education, and to encourage deeper engagement with literature and researchers across these communities. In that spirit, this interactive open-source Quarto document allows readers to peruse the full lists of articles and reference works that make up the field(s) of data science education. Understanding what we can learn from each other can support stronger, more coherent trajectories for future data science students, as well as for all students who will find themselves navigating a data-filled world.

# 1. Why Map Data Science Education Scholarship?

As data science education emerges as a discipline in its own right [@finzer2013; @lee2021; @mike2023; @nationalacademiesofsciencesengineeringandmedicine2018; @nationalacademiesofsciencesengineeringandmedicine2023], still little is known about its core scholarly foundations. This is not surprising, given the rapid evolution of the field of data science and the variety of academic communities that are involved in its development. In many ways, data science education is even more interdisciplinary than data science as a field. Studying the teaching and learning of data science not only involves the content that is being taught, but also requires attention to theories of learning, educational infrastructures, appropriate social science methodologies, and curricular frameworks. There are also multiple established literatures that address some important conceptual foundations of data science [e.g. statistics education, @internat2018; @nolan2010 and computing education; @thecamb2019] and of related topics [e.g. scientific visualization, @edelson1998; data literacies, @pangrazio2019].

Despite these complexities, data science education research and curriculum development races ahead not only at universities but also in K-12 [@weiland2022; @nationalacademiesofsciencesengineeringandmedicine2023], at community colleges [@baumer2023], and in the professional development of teachers [@hudson2024]. It is important to understand how different research communities are approaching data science education, what these communities might learn from each other and from their histories of scholarship, and what this all might mean for the different types of "data science education" students might experience across levels and institutions.

## 1.1 Data Science Education as an Interdisciplinary Field

The earliest programs in data science were born within a variety of departments including statistics, computer science, business analytics, information and library sciences, each with distinctive emphases and approaches. One of the clearest differences in approach to data science education approaches has been between statistics and computer science. A recent scoping review of data science education literature by Msweli and colleagues [-@msweli2023] found that most papers they identified in their search did not explicitly name data science, but rather computer science or statistics, as the home discipline of their work. A pair of workshops offered in 2019 at the ACM's Special Interest Group in Computer Science Education [@cetinkaya-rundel2019] (Cetinkaya-Rundel, Danyluk, et al., 2019) and at the Joint Statistical Meetings (Cetinkaya-Rundel, Posner, et al., 2019), respectively, highlight efforts by both communities to foster collaboration between disciplines.

At the time this analysis was originally developed, there was growing evidence that there were relatively independently developing communities of data science education scholarship emerging. Mike et al [-@mike2023] identified a collection of different themes these communities attended to; and, Rosenberg & Jones [-@rosenberg2024] described how they were drawing from different collections of literature. However, these prior reviews varied dramatically in scope and method, making it difficult to understand the relationship between thematic trends and different foundational literatures. One goal of this ineractive is to offer a living, "meso" level examination that works to map broad emerging themes in the data science education literature to their respective intellectual foundations.

## 1.2 Document Co-Citation Mapping to Understand Interdisciplinary Fields

Science mapping is a form of bibliometric analysis that leverages metadata from published works to characterize the structure of scholarly literatures. It is especially useful for understanding fields that are developing rapidly and that are "voluminous and fragmented" [@aria2017]. Here I rely on co-citation analysis, one of the most popular and validated bibliometric methods [@zupic2015]. Co-citation analysis measures how often certain entities (such as authors, institutions, journals, or documents) appear together in the reference lists of a focal set of papers, assessing entities that appear together more frequently as more conceptually proximal.

Document co-citation analysis in focuses on the individual works that appear together in reference lists. This method is especially useful for mapping the literature base of rapidly-developing fields that may be drawing from diverse academic disciplines and therefore are at risk of developing into isolated subareas [@trujillo2018]. The focal documents for this co-citation analysis are papers that appear in the reference lists of published works that identify the specific phrase “data science education” as a central focus through inclusion in their titles, abstracts, or keywords. The collection of references listed by these works can be understood as the "knowledge base" that informs data science education, and their co-citation frequency and other structural entailments of co-citation patterns can be understood as characterizing the “intellectual structure” of the field [@zupic2015, pp. 11-12].

To better understand the topics that underlie this “intellectual structure,” I employ both qualitative content analysis and bibliographic coupling methods. Qualitative content analysis involves examining the content of papers that comprise each cluster to determine what are their primary student audiences, conceptual themes, teaching strategies, and methodologies. While automated computational topic extraction methods are sometimes used for this purpose, Held [-@held2022] cautions that these are derived from generic clustering algorithms and may not be sufficient for bibliometric analyses. Instead, I manually analyzed paper abstracts and, when required, full texts to determine the specific topics of focus within the data science education scholarship.

Bibliographic coupling allows deeper exploration of what are the products of different knowledge bases, by identifying papers that draw heavily from specific clusters of foundational literature. Following the recommendation in Zupic and Čater [-@zupic2015], I limit bibliographic coupling analysis to only the most recent 5 years of publications. For each cluster, I identify specific papers within the focal set of papers that reference “data science education” as “building on” a specific cluster if they have more than 5 reference works that are included in the bibliographic co-citation analysis, and at least 80% of those references belong to that cluster.

The primary goal of this work is to identify complementary communities of scholars and their area(s) of focus, rather than to make evaluative claims about the impact of certain authors or papers. Additionally, given that different disciplines have different publication norms, over-reliance on quantities such as publication count or citation frequency is especially inappropriate. Therefore, the computational analysis and reporting of findings focus on the structural and conceptual features of co-citation, rather than on assessing the impact of specific authors, communities, or institutions. As Haustein and Larivière [-@haustein2015] emphasize, it is important to recognize bibliometric signals as indicators, not direct measures of impact or significance.

# 2. Constructing the Bibliographic Datasets

This analysis makes extensive use of the R `bibliometrix` package [@aria2017] for constructing, analyzing, and visualizing bibliographic records. I use the `dplyr` package for data handling [@wickham2023], and the `stringr` and `textTools` packages to process and compare scholarly reference records. The `DT` package [@dt:awr2024] is used to generate interactive data displays. All data and code used to generate this document are available for review at [GitHub](https://calcord.github.io/dse-citan/dse_citan.html).

```{r}
#| label: load-packages-and-scripts
#| warning: false

# for the analysis
library(bibliometrix)

# for working with data
library(dplyr)
library(stringr)
library(textTools)

# for a pretty document
library(DT)
```

Consistent with the bibliometric co-citation methods described in Section 1.2, this analysis focuses on three interrelated datasets (also illustrated in [Figure 1](#data-sources)).

-   A collection called `coreDSEworks` describes a core set of 287 scholarly works selected to represent the core, emerging data science education literature. These are indexed academic publications that feature the full phrase "data science education" in the title, abstract, or keywords.

-   A second, much larger collection of scholarly works called `refWorks` represents \[xxx\] distinct papers that are cited by, and are therefore constitute the *de facto* intellectual foundations of, the emerging data science education literature. This dataset is constructed by extracting references from the bibliographies of each record in `coreDSEworks`. Since papers in `coreDSEworks` cite one another, many appear in both datasets.

-   The dataset `bibNetwork` describes a weighted document co-citation network of `refWorks`. It represents each record in `refWorks` as a node in the network. The more frequently a given reference document is cited by the core works, the higher the weight of the corresponding node in `bibNetwork`. Two nodes in the network are connected by an edge when both works appear in the reference list of the same core document (A, B, C, etc.). The more frequently two nodes appear together in the reference lists of core documents, the heavier the weight of the corresponding edge.

-   A human-interpretable index `shortname` is constructed and used to link records across the three distinct datasets.

![Bibliographic Datasets. Three key datasets: coreDSEworks describes a collection of papers centrally focused on “data science education,” refWorks includes all papers that appear in the reference lists of coreDSEworks, and bibNetwork describes co-citation patterns between refWorks as a weighted network.](static/datasources.png){#data-sources}

## 2.1 Identifying "Core" Data Science Education Publications

This review is focused on an intentionally narrow, but relevant and well-specified set of initial works to form the “core” set of papers meant to represent the field: publications that are indexed in either Scopus or Clarivate Analytics Web of Science and that include the specific full phrase “data science education” in the title, abstract, or keywords. I remove records deemed inappropriate, including correction statements (for which corrected reports remain included), retraction statements and their corresponding retracted articles, full conference review records, and full poster session review records. For excluded full proceedings records, I confirm that any more specific corresponding records are included when available.

```{r}
#| label: get-core-works
#| output: false

source("scripts/read_works.R")
coreDSEworks <- getCoreDSEWorks()
```

The histogram featured in Figure 3 reflects the nascent nature of this area of study, with the first publication appearing in 2012 and relatively steady growth since then.

```{r}
#| label: show-pub-years

# use breaks to make sure empty bins (2013) still show
hist(coreDSEworks$PY, breaks=seq(2011,2025,1), xaxt='n')

# shuffle the axis to place each year in center of the corresponding bar
axis(side=1, at=seq(2011.5,2024.5, 1), labels=seq(2012,2025,1))
```

To help confirm that this is a reasonable set of publications to begin with, Table 1 below previews records from the `coreDSEworks` dataset. While there may be some expected works missing from the set, the goal is for the `coreDSEworks` set to reasonably represent a core set of scholarly papers that all center the study and practice of data science education.

```{r}
#| label: display-core-works

datatable(coreDSEworks[
  sample(1:nrow(coreDSEworks)), 
  c(1,5,4,6)],
  colnames=c('Author','Year','Title', 'Source'),
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

Of the publication records that are included in the `coreDSEworks` dataset, there are some that do not include information about cited references. Manual inspection reveals that typically these records are editorials and commentaries. Since these works represent substantive contributions to the literature, and provide information about the venues and authors that are actively contributing to the “data science education” discourse, they are not excluded from this dataset. However, because they works do not include reference lists, such records also do not directly impact the construction of the reference co-citation network that is described in the following sections.

## 2.2 Extracting and Cleaning DSE Reference Works

Next, construct a new dataset called `refWorks` to represent the full set of works cited by the "data science education" papers included `coreDSEworks`. This is done by extracting each cited paper from the full cited references list of each `coreDSEworks` paper.

```{r}
#| label: extract-reference-works
#| warnings: false

refWorks <- as.data.frame(
  citations(coreDSEworks, field = "article", sep = ";")$Cited)
```

As noted by Mike et al [-@mike2023], processing reference data is not trivial. The cited reference lists included in Scopus and WoS databases are text-only, and the formats that are used across the style guides of various disciplines engaged in data science education (e.g. Association for Computing Machinery, American Psychological Association, Institute of Electrical and Electronics Engineers) are quite different. Even more standardized ways of citing references, such as the Document Object Identifier number (DOI), are not always included in reference lists or available for all relevant publications.

These difficulties are most likely to arise for higher-profile papers that have been picked up by different scholarly communities, and are therefore cited in multiple formats. Consider, for example, the National Academies' [-@nationalacademiesofsciencesengineeringandmedicine2018] report *Data Science for Undergraduates: Opportunities and Options* report. Table 2 features several records which match the substring “data science for undergraduates.” The majority of matching records were intended to represent that report, but have been extracted and tallied as distinct references.

```{r}
#| label: demo-duplicates
#| output: true

showabit <- refWorks %>% filter( CR %like% "DATA SCIENCE FOR UNDERGRADUATES" ) %>% head(20)
datatable(showabit,
  rownames=FALSE,
  colnames=c('Cited Reference','Freq'),
  options=list(pageLength=5, class='compact stripe')
)
```

If records such as the ones above are not consolidated, the well-known *Data Science for Undergraduates* report [-@nationalacademiesofsciencesengineeringandmedicine2018] would be represented in the network as several isolated papers, each with only marginal impact on the field as a whole. To address this problem of duplicate records and ensure that the resulting reference co-citation network is accurate, turn `refWorks` into a lookup table. Using a combination of methods including removal of special characters, automated text matching, and a manual dictionary of duplicate records screened by author and year, each text reference is mapped to a single parent format.

```{r}
#| label: generate-lookup-table
#| output: false

source("scripts/clean_refs.R")
charExcludeList <- '[\r\n\\:\\(\\)+\\?\\|\\"\\“\\”\\,\'\\`\\‘\\.\\*\\’]'
refWorks$CR <- gsub(charExcludeList,'',refWorks$CR) # the original cited works
 
refWorks$correctedCR <- ""
refWorks$freqAgg <- refWorks$Freq
 
refWorks <- cleanSpecialChars(refWorks) 
# NOTE The Aug 2025 update to refs removed multiple authors from many records. 
# I use manualdupes.txt to retain original references when they have more info.
refWorks <- cleanManualDuplicates(refWorks) 
# NOTE By removing multiple authors, the Aug 2025 update also made false automatch 
# more likely. I've increased sensitivity from .75 to .8
refWorks <- autoMatch(refWorks,.80)

paste0("There are now ",count(refWorks)," records in refWorks.")
```

The lookup table is then used to replace all duplicate versions of a given reference that appear in the text reference lists within the `coreDSEworks` dataset with the corrected parent reference text. The total citation frequency for each reference is then recalculated by counting the number of `coreDSEworks` that include each corrected parent reference.

```{r}
#| label: tally-corrected-refs-in-coreDSEworks
#| output: true

 # Replace refs lists in the core works datatable with cleaned refs
 coreDSEworks <- rewriteCleanRefs(coreDSEworks,charExcludeList)
 
 # update frequencies given found matches in coreDSEworks
 refWorks <- correctFrequenciesCited(refWorks,coreDSEworks)
```

After this round of cleaning, citation counts for references that appeared multiple times in the list are consolidated.

```{r}
#| label: show-corrected-refs

datatable(refWorks[c(3,5)] %>% 
            arrange(desc(refWorks$freqCit)) %>% 
            head(100),
  colnames=c('Cited Reference','# Citing DSE Works'),
  rownames=FALSE,
  options=list(pageLength=5, class='compact stripe')
)
```

## 2.3 Indexing Between Core and Reference Works

To facilitate interpretation of the results, create unique document indices to link reference records across datasets. The indices leverage a naming convention that is also employed by the bibliometrix analysis package when it generates a co-citation network from bibliographic data (see Section 3.2). Each reference document is assigned a name in the format: author last name, author first initial(s), year of publication (for example, conway d 2010). An attribute is also added to each `coreDSEworks` record, which stores the shortnames for all of that record’s cited references.

```{r}
#| label: generate-shortnames

source("scripts/shortnames.R")
# create shortnames and add them as a new ref list to coreDSEworks
refWorks <- refShortNames(refWorks)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)
```

In cases where more than one distinct reference record exists with the same identifier, shortnames are each appended with a number, by descending citation frequency of their corresponding record.

Records in the coreDSEworks dataset are much more robust, with information parsed into relevant columns (e.g. author, year, source, title, etc.) while refWorks records are simple strings reflecting a variety of ill-defined and at times difficult-to-parse formats. Within refWorks, the most common format for these strings, which are meant to represent a full reference, begins with an author list, followed by title and source information, and ends with the year. To introduce consistency in the presentation of results across datasets given these limitations, all reference tables presented in the results section will follow the same format including the first author, year, and full available reference information in separate columns. Full references of coreDSEworks records will be re-formatted to follow the most common full reference format in refWorks.

# 3. Constructing the Reference Co-Citation Network

Finally, a bibliographic co-citation network is constructed using the cleaned and consolidated reference records. I limit the network to include only reference works that were cited at least 3 times in order to focus on repeated reference patterns that are suggestive of community practices, rather than spurious relationships that are limited to only one or a few papers.

```{r}
#| label: generate-ref-net
# build co-citation network of DSE cited works
refMatrix <- biblioNetwork(coreDSEworks, analysis = "co-citation",
                           network = "references", sep = "; ", short=TRUE)
```

Identify clusters using the Leiden community detection algorithm. This is a form of clustering that seeks to maximize the connectedness of nodes *within* vs *between* clusters, whilst maintaining that each community’s nodes are internally connected [@traag2019]. Leiden determines the number of clusters automatically as it maximizes the modularity score (internal vs cross-cluster connections). In the context of bibliographic analysis, this means the algorithm identifies both the number and composition of scholarly communities as represented by more frequently co-cited works and ensures that each work within a given community is connected to each other community member through an internal path of co-citations.

The Leiden community detection algorithm is not deterministic. Each time the code is run, the output is different. The analysis below takes steps to reduce uncertainty by separating boundary works (which are likely change cluster membership across runs) from core cluster nodes, and by focusing on general trends rather than relying on specific papers when making claims about the nature and composition of clusters. I also suggest running the analysis multiple times to examine the stability of results, and comparing results to two alternative community identification algorithms that are available in the bibliometrix package and commonly used in bibliographic analysis [Louvain and Walktrap; @subelj2016].

## 3.1 The Reference Co-Citation Network, Visualized

Figure 3 features a visualization of the reference co-citation network with all shortnames visible using the Fructerman-Reingold layout algorithm [@fruchterman1991]. More highly cited references are represented by larger nodes, and each node’s spatial position generally approximates that node’s “closeness,” in terms of co-citation patterns, to other nearby reference nodes. In other words, nodes that are closer spatially are more likely to be co-cited together, or to be more closely related through co-citation chains. Nodes positioned between two clusters generally represent reference works that are co-cited alongside otherwise distinct sets of literature.

```{r}
#| label: visualize-ref-net

inclusion.cite.count = 2
cutoff = as.integer(count(refWorks %>% 
                            filter(freqCit>inclusion.cite.count)))

refNet=networkPlot(refMatrix, n=cutoff,
                   Title = "Co-Citation Network of Top DSE Reference Works",
                   size.cex=TRUE, size=10, remove.multiple=FALSE,
                   remove.isolates = TRUE, labelsize=0, edgesize = 5,
                   edges.min=0, type = "fruchterman", cluster = "leiden",
                   community.repulsion = .04)

# we created shortnames for all duplicates, but refNet will 
# only create shortnames for items that are cited at least the 
# inclusion.cite.count number of times. Let's update to that.
refWorks <- refShortNames(refWorks,inclusion.cite.count)
coreDSEworks <- coreShortNames(coreDSEworks,refWorks)

# also export a pajek file from the network that I can use to generate a nicer visualization for the paper
net2Pajek(refNet,"data/refNet")
```

::: callout-note
**NOTE!** Both the clustering and layout algorithms used for this analysis have stochastic elements. It's not unlikely that things will shake out differently across runs. Consider the stability of results, and the nature and composition (rather than only assignment/coloring) of clusters as you work to interpret the results.

For an example of deeper interpretation of results from an earlier version of this analysis, please consult the article [Wilkerson, M. H. (2025). Mapping the Conceptual Foundation(s) of "Data Science Education". *Harvard Data Science Review, 7*(3). doi: ](https://hdsr.mitpress.mit.edu/pub/1vd80i9t/release/2)<https://doi.org/10.1162/99608f92.9ac68105>
:::

## 3.2 Broker Works: Papers Cited by the Data Science Education Field at Large

A broker describes a node in a network that connects otherwise distinct communities. Brokers are characterized by high betweenness centrality, which measures the degree to which a given node offers the shortest path (or in this case, is most closely connected through chains of co-citation) between other pairs of nodes in the network. In the visualization above, these works can be identified visually as the nodes that are positioned more centrally within the global network. In the context of bibliographic networks, broker nodes reflect scholarly “bridges” that appear in reference lists alongside otherwise distinct collections of work. This suggests these works have higher visibility and serve to establish common ground across communities.

The top ten broker works as identified by betweenness centrality are featured in the table below.

```{r}
#| label: pull-top-brokers

# select the most "between" reference works. Show the top ten
# and include the top 50
refBrokers <- refNet[["cluster_res"]] %>% 
  arrange(desc(btw_centrality)) %>%
  head(50)

# use shortnames to identify the full citation for each
# reference broker work from the refWorks data frame
refBrokers$vertex <- paste0(
  word(refBrokers$vertex,1), " ",
  str_sub(word(refBrokers$vertex,2),1,1), " ",
  word(refBrokers$vertex,3))

# refNet is shortnaming most popular with -1; fix for the join
refBrokers$vertex <- sub("(\\d{4})-1","\\1",refBrokers$vertex)

##### TODO: what is going on with dalton c 2016? shortnames seem to match fine

relevantRefs <- refWorks %>% 
  filter(shortname %in% refBrokers$vertex) %>% 
  filter(freqCit > inclusion.cite.count) %>% 
  arrange(desc(freqCit))

datatable(left_join(refBrokers, relevantRefs, by=c("vertex"="shortname") )[c(11,12,8,10)],
  rownames=FALSE,
  colnames=c('First Author','Year','Cited Reference', '# Citing DSE Works'),
  options=list(pageLength=10, class='compact stripe')
)
```

# 4. Characterizing the Foundational Literatures of Data Science Education

Let's try to describe each of the clusters that were identified through the methods above. Below, for each cluster, only references that fall below the 80^th^ percentile of betweenness centrality are listed. I refer to these as “cluster isolates.” By filtering the dataset in this way, we can focus only on the research papers that are unique to each cluster, that is, they are only cited alongside other reference works that are members of the same cluster. This also lessens the risk of drawing incorrect interpretations of clusters due to the uncertainty built into algorithms that determine and visualize cluster membership of bridging works. The code below sets up to extracts the cluster isolates for each cluster identified in the analysis above.

In the original version of this analysis published in July '25, three relatively stable clusters were identified. This may change as more records are added to the document and new citation patterns emerge. Therefore, I've set the document up to describe up to five clusters. Some may be empty if fewer than five clusters were identified.

```{r}
#| label: prepare-to-extract-clusters

y <- refNet[["cluster_res"]]$btw_centrality
y[y==0] <- NA

# set the cutoff to lowest 80th percentile in terms of betweenness centrality
btw_cutoff <- quantile(y,c(.8),na.rm=TRUE)

referenceClusterAuthors <- refNet[["cluster_res"]] %>%
  # restrict this to only authors of papers that are not very connected
  # outside of their specific cluster
  #filter( btw_centrality < mean(refNet[["cluster_res"]]$btw_centrality) ) %>%
  filter( btw_centrality < btw_cutoff ) %>%
  group_by(cluster) %>%
  summarize(authors = list(
    paste(
      word(vertex,1),  # first word (last name)
      str_sub(word(vertex,2),1,1),     # second word (first initial)
      word(vertex,3) )
    )
  )

getClusterHub <- function(i) {
  clusterLookup <- referenceClusterAuthors$authors[[i]]
  return( refWorks %>%
    filter( !is.na( shortname ) ) %>% 
    filter( shortname %in% clusterLookup ) %>%
    filter( freqCit > 2 ) %>%
    arrange( desc(freqCit) ) )
}

# add $refInfo as quick lookup for what cluster the refs belong to
for( i in 1:nrow(coreDSEworks) ) {
  coreDSEworks$refInfo[i] <- refNet[["cluster_res"]] %>% 
       filter( str_detect(vertex, coreDSEworks$shortnameRefs[i]) == TRUE ) %>% 
    select(cluster)
}

getHeavyCitingWorks <- function(coreDSEworks,n,range="[1-3]") {
  # filter to look at works citing at least 5 DSE refWorks
  coreCitingWorks <- coreDSEworks %>% 
    filter( str_count(coreDSEworks$refInfo,range) > 5 )
  
  # then only include those that have >80% reWorks from cluster n
  coreCitingWorks <- coreCitingWorks %>% 
    filter( str_count(coreCitingWorks$refInfo,as.character(n))
            /str_count(coreCitingWorks$refInfo,range) > .8 )
  
  # filter out older than 5 years
  coreCitingWorks <- coreCitingWorks %>% 
    filter( coreCitingWorks$PY > 2019 )
  
  return( coreCitingWorks )
}
```

## Cluster 1

The members of cluster 1 isolate are:

```{r}
#| label: see-cluster-hub-1

datatable(getClusterHub(1)[c(6,7,3,5)],
  rownames=FALSE,
  colnames=c('First Author','Year','Cited Reference', '# Citing DSE Works'),
  options=list(pageLength=10, class='compact stripe')
)
```

### Recent Citing Works

Using the shortname identifiers, a co-citation coupling analysis can identify recent coreDSEworks that heavily cite papers from this cluster. The DSE works whose citation list features 80% or more refWorks-indexed works from Cluster 1 are:

```{r}
#| label: find-citing-core-works-cluster1
#| warning: false

coreCitingWorks1 <- getHeavyCitingWorks(coreDSEworks,1)

datatable(coreCitingWorks1[c(85,5,86)],
  rownames=FALSE,
  colnames=c('First Author','Year','Citing Paper'),
  options=list(pageLength=5, class='compact stripe')
)
```

## Cluster 2

The members of cluster 2 isolate are:

```{r}
#| label: see-cluster-hub-2

datatable(getClusterHub(2)[c(6,7,3,5)],
  rownames=FALSE,
  colnames=c('First Author','Year','Cited Reference', '# Citing DSE Works'),
  options=list(pageLength=10, class='compact stripe')
)
```

### Recent Citing Works

The DSE works whose citation list features 80% or more refWorks-indexed works from Cluster 2 are:

```{r}
#| label: find-citing-core-works-cluster2
#| warning: false

coreCitingWorks2 <- getHeavyCitingWorks(coreDSEworks,2)

datatable(coreCitingWorks2[c(85,5,86)],
  rownames=FALSE,
  colnames=c('First Author','Year','Citing Paper'),
  options=list(pageLength=5, class='compact stripe')
)
```

## Cluster 3

The members of cluster 3 isolate are:

```{r}
#| label: see-cluster-hub-3

datatable(getClusterHub(3)[c(6,7,3,5)],
  rownames=FALSE,
  colnames=c('First Author','Year','Cited Reference', '# Citing DSE Works'),
  options=list(pageLength=10, class='compact stripe')
)
```

### Citing Works

The DSE works whose citation list features 80% or more refWorks-indexed works from Cluster 3 are:

```{r}
#| label: find-citing-core-works-cluster3
#| warning: false

coreCitingWorks3 <- getHeavyCitingWorks(coreDSEworks,3)

datatable(coreCitingWorks3[c(85,5,86)],
  rownames=FALSE,
  colnames=c('First Author','Year','Citing Paper'),
  options=list(pageLength=5, class='compact stripe')
)
```

## Cluster 4

The members of cluster 4 isolate are:

```{r}
#| label: see-cluster-hub-4

datatable(getClusterHub(4)[c(6,7,3,5)],
  rownames=FALSE,
  colnames=c('First Author','Year','Cited Reference', '# Citing DSE Works'),
  options=list(pageLength=10, class='compact stripe')
)
```

### Citing Works

The DSE works whose citation list features 80% or more refWorks-indexed works from Cluster 4 are:

```{r}
#| label: find-citing-core-works-cluster4
#| warning: false

coreCitingWorks4 <- getHeavyCitingWorks(coreDSEworks,4)

datatable(coreCitingWorks4[c(85,5,86)],
  rownames=FALSE,
  colnames=c('First Author','Year','Citing Paper'),
  options=list(pageLength=5, class='compact stripe')
)
```

## Cluster 5

The members of cluster 5 isolate are:

```{r}
#| label: see-cluster-hub-5

datatable(getClusterHub(5)[c(6,7,3,5)],
  rownames=FALSE,
  colnames=c('First Author','Year','Cited Reference', '# Citing DSE Works'),
  options=list(pageLength=10, class='compact stripe')
)
```

### Citing Works

The DSE works whose citation list features 80% or more refWorks-indexed works from Cluster 5 are:

```{r}
#| label: find-citing-core-works-cluster5
#| warning: false

coreCitingWorks5 <- getHeavyCitingWorks(coreDSEworks,5)

datatable(coreCitingWorks5[c(85,5,86)],
  rownames=FALSE,
  colnames=c('First Author','Year','Citing Paper'),
  options=list(pageLength=5, class='compact stripe')
)
```

## 

# 6. References
