print("Cluster 4/n")
print(head(arrange(cleanRecords, desc(CL4), CL4),5)[c("SR","CL4")])
print("Cluster 1\n")
print(head(arrange(cleanRecords, desc(CL1), CL1),5)[c("SR","CL1")])
print("Cluster 2\n")
print(head(arrange(cleanRecords, desc(CL2), CL2),5)[c("SR","CL2")])
print("Cluster 3/n")
print(head(arrange(cleanRecords, desc(CL3), CL3),5)[c("SR","CL3")])
print("Cluster 4/n")
print(head(arrange(cleanRecords, desc(CL4), CL4),5)[c("SR","CL4")])
View(cleanRecords)
print("Cluster 1\n")
print(head(arrange(cleanRecords, desc(CL1), CL1),10)[c("SR","CL1")])
print("Cluster 2\n")
print(head(arrange(cleanRecords, desc(CL2), CL2),10)[c("SR","CL2")])
print("Cluster 3/n")
print(head(arrange(cleanRecords, desc(CL3), CL3),10)[c("SR","CL3")])
print("Cluster 4/n")
print(head(arrange(cleanRecords, desc(CL4), CL4),10)[c("SR","CL4")])
View(netMatrix)
net100[["cluster_res"]]
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "references",
network = "references", sep = ";")
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "co-citation",
network = "authors", sep = ";")
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "co-citation",
network = "author", sep = ";")
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "coupling",
network = "references", sep = ";")
networkPlot(netMatrix2)
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "co-citation",
network = "authors", sep = ";")
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "co-occurrences",
network = "references", sep = ";")
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "authors,
""
;
)
"
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "authors",
network = "references", sep = ";")
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "collaboration",
network = "references", sep = ";")
coupling
netMatrix2 <- biblioNetwork(cleanRecords, analysis = "coupling",
network = "references", sep = ";")
networkPlot(netMatrix2)
net2VOSviewer(networkPlot(netMatrix2))
net100[["cluster_res"]]
cleanRecords$CLSFARD<- str_count(cleanRecords$CR,
)
cleanRecords$CLSFARD<- str_count(cleanRecords$CR,
regex('sfard',
ignore_case = T))
print(head(arrange(cleanRecords, desc(CLSFARD), CLSFARD),100)[c("SR","CLSFARD")])
net2VOSviewer(net100,".")
cleanRecords$CLSBEIH<- str_count(cleanRecords$CR,
regex('biehler',
ignore_case = T))
cleanRecords$CLSBEIH
head(arrange(cleanRecords, desc(CLSBEIH), CLSBEIH),10)[c("SR","CLSBEIH")]
head(arrange(cleanRecords, desc(CLSFARD), CLSFARD),10)[c("SR","CLSFARD")]
View(net100)
View(local_cluster_authors)
View(myRefs)
View(local_cluster_authors)
View(cleanRecords)
print("CLUSTER 3")
print(head(arrange(cleanRecords, desc(CL3), CL3),10)[c("SR","CL3")])
print("CLUSTER 4")
print(head(arrange(cleanRecords, desc(CL4), CL4),10)[c("SR","CL4")])
print(head(arrange(cleanRecords, desc(CL1)),10)[c("SR","CL1")])
print(head(arrange(cleanRecords, desc(CL1)),10)[c("SR")])
head(arrange(cleanRecords, desc(CL1)),10)[c("SR")]
head(arrange(cleanRecords, desc(CL1)),10)[c("SR","CL1")]
print(head(arrange(cleanRecords, desc(CL2), CL2),10)[c("CL2")])
head(arrange(cleanRecords, desc(CL1)),10)[c("CL1")]
print("CLUSTER 1")
head(arrange(cleanRecords, desc(CL1)),10)[c("CL1")]
print("CLUSTER 2")
print(head(arrange(cleanRecords, desc(CL2), CL2),10)[c("CL2")])
print("CLUSTER 3")
print(head(arrange(cleanRecords, desc(CL3), CL3),10)[c("CL3")])
print("CLUSTER 4")
print(head(arrange(cleanRecords, desc(CL4), CL4),10)[c("CL4")])
net100[["cluster_res"]]
net100
View(net100)
View(netMatrix)
View(net100)
net100[["nodeDegree"]][["degree"]]
net100[["nodeDegree"]]
net100[["graph"]]
net100[["cluster_obj"]]
View(local_cluster_authors)
net100[["cluster_res"]]
print("TOP CORE PAPERS CITING CLUSTER 1")
head(arrange(cleanRecords, desc(CL1)),10)[c("CL1")]
print("TOP CORE PAPERS CITING CLUSTER 2")
head(arrange(cleanRecords, desc(CL2), CL2),10)[c("CL2")]
print("TOP CORE PAPERS CITING CLUSTER 3")
head(arrange(cleanRecords, desc(CL3), CL3),10)[c("CL3")]
View(local_cluster_authors)
print("TOP CORE PAPERS CITING CLUSTER 4")
head(arrange(cleanRecords, desc(CL4), CL4),10)[c("CL4")]
net1000=networkPlot(netMatrix, n = 1000,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net1000,".")
net1000=networkPlot(netMatrix, n = 500,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net500,".")
net500=networkPlot(netMatrix, n = 500,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net500,".")
cleanRecords$CL1 <- length(unique(c(str_count(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T)))))
print("TOP CITED PAPERS IN CLUSTER 1")
head(arrange(cleanRecords, desc(CL1)),10)[c("CL1")]
# Identify the top citers for each cluster of referenced works. Not yet elegant,
# just getting this done for the preliminary submission.
cleanRecords$CL1 <- str_count_unique(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
# Identify the top citers for each cluster of referenced works. Not yet elegant,
# just getting this done for the preliminary submission.
cleanRecords$CL1 <- str_counts(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
library(textTools)
install.packages("textTools")
library(textTools)
# Identify the top citers for each cluster of referenced works. Not yet elegant,
# just getting this done for the preliminary submission.
cleanRecords$CL1 <- str_counts(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
str_locate(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
str_subset(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
str_extract(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
length(unique(str_extract(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))))
unique(str_extract(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T)))
cleanRecords %<% str_extract(CR, regex(local_cluster_authors$vertex[1], ignore_case = T))
cleanRecords %>% str_extract(CR, regex(local_cluster_authors$vertex[1], ignore_case = T))
str_extract(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
str_count_intersect(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
str_count(cleanRecords$CR,
regex(local_cluster_authors$vertex[1],
ignore_case = T))
View(local_cluster_authors)
View(local_cluster_authors)
View(myRefs)
View(local_cluster_authors)
View(net100)
View(local_cluster_authors)
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
(vertex = sprintf(word(vertex))) #paste(word(vertex), collapse = "|"))
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(vertex = sprintf(word(vertex))) #paste(word(vertex), collapse = "|"))
View(local_cluster_authors)
View(local_cluster_authors)
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = sprintf(word(vertex))) #paste(word(vertex), collapse = "|"))
View(local_cluster_authors)
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = collapse(word(vertex),'')) #paste(word(vertex), collapse = "|"))
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = paste(word(vertex),collapse='')) #paste(word(vertex), collapse = "|"))
View(local_cluster_authors)
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = c(word(vertex))) #paste(word(vertex), collapse = "|"))
View(local_cluster_authors)
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
mutate(authors = c(word(vertex))) #paste(word(vertex), collapse = "|"))
View(local_cluster_authors)
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = c(word(vertex))) #paste(word(vertex), collapse = "|"))
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = c(word(vertex)), .groups="keep") #paste(word(vertex), collapse = "|"))
View(local_cluster_authors)
# get first author names of member authors for each cluster
local_cluster_authors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = list(word(vertex))) #paste(word(vertex), collapse = "|"))
View(local_cluster_authors)
# Identify the top citers for each cluster of referenced works. Right now
# this is just looking at first author's name (duplicates are typically self-
# citations which are less useful to understand intellectual foundations).
cleanRecords$CL1 <- str_count_intersect(cleanRecords$CR,
regex(local_cluster_authors$authors[1],
ignore_case = T))
# Identify the top citers for each cluster of referenced works. Right now
# this is just looking at first author's name (duplicates are typically self-
# citations which are less useful to understand intellectual foundations).
cleanRecords$CL1 <- str_count_intersect(cleanRecords$CR, local_cluster_authors$authors[1],
ignore_case = T)
# Identify the top citers for each cluster of referenced works. Right now
# this is just looking at first author's name (duplicates are typically self-
# citations which are less useful to understand intellectual foundations).
cleanRecords$CL1 <- str_count_intersect(cleanRecords$CR, local_cluster_authors$authors[1])
head(arrange(cleanRecords, desc(CL1)),10)[c("CL1")]
# Identify the top citers for each cluster of referenced works. Right now
# this is just looking at first author's name (duplicates are typically self-
# citations which are less useful to understand intellectual foundations).
cleanRecords$CL1 <- str_counts(cleanRecords$CR, local_cluster_authors$authors[1])
strsplit("test test"," ")
View(local_cluster_authors)
str_count_intersect((lapply(strsplit(cleanRecords$CR," ")), tolower), local_cluster_authors$authors[1])
str_count_intersect( lapply( strsplit(cleanRecords$CR," "), tolower), local_cluster_authors$authors[1])
strsplit(cleanRecords$CR," ")
View(cleanRecords)
test <- cleanRecords
test$refs <- list(strsplit(CR, ";"))
test$refs <- list(strsplit(test$CR, ";"))
View(test)
View(test)
test$countrefs <- count(test$refs)
net2VOSviewer(net100,".")
net25=networkPlot(netMatrix, n = 25,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net25,".")
net2VOSviewer(net40,".")
net40=networkPlot(netMatrix, n = 40,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net40,".")
net200=networkPlot(netMatrix, n = 200,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net200,".")
net500=networkPlot(netMatrix, n = 500,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net500,".")
net500=networkPlot(netMatrix, n = 500,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net500,".")
View(net100)
net100 %<% order_by(nodeDegree)
net100 %>% order_by(nodeDegree)
net100 %>% arrange(nodeDegree)
head(net100$nodeDegree,5)
head(net100$nodeDegree,15)
net100=networkPlot(netMatrix, n = 100,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
net2VOSviewer(net100,".")
View(net100)
View(myRefs)
View(net100)
View(netMatrix)
View(net100)
View(local_cluster_authors)
View(net100)
rm("net*")
rm("net1000")
rm("net200")
rm("net500")
rm("net40")
rm("net425")
rm("net25")
CR <- citations(M, field = "article", sep = ";")
CR <- citations(cleanRecords, field = "article", sep = ";")
cbind(CR$Cited[1:20])
CR <- citations(cleanRecords, field = "article", sep = ";")
cbind(CR$Cited[1:100])
CR <- citations(cleanRecords, field = "article", sep = ";")
cbind(CR$Cited[1:150])
View(results)
# build co-citation network of DSE cited works
netMatrix <- biblioNetwork(results, analysis = "co-citation",
network = "references", sep = ";")
results$MostCitedPapers
results$Documents
rm(CR)
refsCited <- citations(cleanRecords, field = "article", sep = ";")
View(refsCited)
bibliometrixData::
bibliometrixData
refsCited$Year
# get first author names of member authors for each cluster
coreClusterAuthors <- net100[["cluster_res"]] %>%
# restrict this to only authors of papers that are not very connected
# outside of their specific cluster
filter( btw_centrality < 100 ) %>%
group_by(cluster) %>%
summarize(authors = list(word(vertex))) #paste(word(vertex), collapse = "|"))
referenceWorks %<% filter(Cited == 3)
referenceWorks %>% filter(Cited == 3)
library(agop)
library(bibliometrix)
library(dplyr)
library(stringr)
library(textTools)
scopus <- convert2df(file = "./data/scopus.csv", dbsource = 'scopus',
format = "csv")
# 276 from Scopus
wos <- convert2df(file = "./data/wos.txt", dbsource = 'wos',
format = "plaintext")
coreDSEworks <- mergeDbSources(scopus, wos)
# rm-list.txt identifies: records that are so incomplete that the text cannot
# be found; records that are duplicated; and records the represent full
# proceedings documents for conferences that were not primarily focused on
# data science education. I identified these manually.
stoplist <- scan("rm-list.txt", what="", sep="\n")
coreDSEworks <- coreDSEworks[ ! coreDSEworks$UT %in% stoplist, ]
# Some records (e.g. websites, reference works) do not have TI populated
# This duplicates the SO col to TI to make the record user-friendly
titlelist <- scan("title-list.txt", what="", sep="\n")
for(ut in titlelist) { coreDSEworks["TI"][coreDSEworks["UT"]==ut] <-
coreDSEworks["SO"][coreDSEworks["UT"]==ut] }
# summary results of core DSE works
coreBibAnalysis <- biblioAnalysis(data.frame(coreDSEworks))
summary(results, max=10)
summary(coreBibAnalysis, max=10)
referenceWorks <- citations(coreDSEworks, field = "article", sep = ";")
# build co-citation network of DSE cited works
referenceMatrix <- biblioNetwork(coreDSEworks, analysis = "co-citation",
network = "references", sep = ";")
referenceWorks %>% filter(Cited>2)
referenceWorks[lapply[referenceWorks, >2]]
list.filter(referenceWorks, Cited>2)
library(purrr)
keep(referenceWorks, Cited>3)
keep(referenceWorks, referenceWorks$Cited>3)
referenceWorks$Cited
View(referenceWorks)
referenceWorks$Cited$Value
citedWorks <- referenceWorks$Cited
citedWorks
referenceWorks[["Cited"]][["DATA SCIENCE FOR UNDERGRADUATES: OPPORTUNITIES AND OPTIONS, (2018)"]]
referenceWorks[["Cited"]]
referenceWorks$Cited
referenceWorks$Cited[[1]]
referenceWorks$Cited[[2]]
referenceWorks$Cited[[3]]
keep(referenceWorks, function(x) referenceWorks$Cited[x] > 3)
rlang::last_error()
rlang::last_trace()
keep(referenceWorks, function(x) referenceWorks$Cited[[x]] > 3)
typeof(referenceWorks)
View(referenceMatrix)
test <- referenceWorks[["Cited"]]
test[1]
test[2]
test <- referenceWorks[["Cited"]][1]
test <- referenceWorks[["Cited"]][2]
referenceWorks[["Cited"]][2]
referenceWorks[["Cited"]][[2]
]
count(referenceWorks[["Cited"]][[2]])
count(referenceWorks[["Cited"]][[x]])
length(referenceWorks[["Cited"]][[x]])
length(referenceWorks[["Cited"]][[2]])
length(referenceWorks[["Cited"]][[1]])
length(referenceWorks[["Cited"]])
length(referenceWorks[["Cited"]][])
length(referenceWorks[[2]])
referenceWorks[[2]]
referenceWorks[[1]]
referenceWorks[[3]]
referenceWorks$CR
test$CR
referenceWorks[[3]]
referenceWorks[[1]][[1]]
referenceWorks[[1]][[2]]
referenceWorks[[1]][[3]]
referenceWorks
testdf <- as.data.frame(referenceWorks$Cited)
testdf %>% filter(Freq>3)
testdf <- as.data.frame(referenceWorks$Cited)
library(agop)
library(bibliometrix)
library(dplyr)
library(stringr)
library(textTools)
scopus <- convert2df(file = "./data/scopus.csv", dbsource = 'scopus',
format = "csv")
# 276 from Scopus
wos <- convert2df(file = "./data/wos.txt", dbsource = 'wos',
format = "plaintext")
coreDSEworks <- mergeDbSources(scopus, wos)
# rm-list.txt identifies: records that are so incomplete that the text cannot
# be found; records that are duplicated; and records the represent full
# proceedings documents for conferences that were not primarily focused on
# data science education. I identified these manually.
stoplist <- scan("rm-list.txt", what="", sep="\n")
coreDSEworks <- coreDSEworks[ ! coreDSEworks$UT %in% stoplist, ]
# Some records (e.g. websites, reference works) do not have TI populated
# This duplicates the SO col to TI to make the record user-friendly
titlelist <- scan("title-list.txt", what="", sep="\n")
for(ut in titlelist) { coreDSEworks["TI"][coreDSEworks["UT"]==ut] <-
coreDSEworks["SO"][coreDSEworks["UT"]==ut] }
# summary results of core DSE works
coreBibAnalysis <- biblioAnalysis(data.frame(coreDSEworks))
summary(coreBibAnalysis, max=10)
# get a data frame of the references.
referenceWorks <- as.data.frame(citations(coreDSEworks, field = "article", sep = ";")$Cited)
# build co-citation network of DSE cited works
referenceMatrix <- biblioNetwork(coreDSEworks, analysis = "co-citation",
network = "references", sep = ";")
# set a cut off of number of cites for a paper to qualify as refNet member
cutoff <- count(referenceWorks %>% filter(Freq>3))
rm(cutoff)
# build co-citation network of DSE cited works
referenceMatrix <- biblioNetwork(coreDSEworks, analysis = "co-citation",
network = "references", sep = ";")
# set a cut off of number of cites for a paper to qualify as refNet member
cutoff = count(referenceWorks %>% filter(Freq>3))
refNet=networkPlot(referenceMatrix, n = cutoff,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
rm(cutoff)
# set a cut off of number of cites for a paper to qualify as refNet member
cutoff = as.integer(count(referenceWorks %>% filter(Freq>3)))
refNet=networkPlot(referenceMatrix, n = cutoff,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
refNet=networkPlot(referenceMatrix, n = 71,
Title = "Co-Citation Network of Top 100 Cited Papers",
size.cex=TRUE, size=15, remove.multiple=FALSE,
remove.isolates = TRUE, labelsize=.7, edgesize = 5,
edges.min=0, type = "fruchterman", cluster = "louvain")
